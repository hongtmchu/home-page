<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Andrew Heiss">
<meta name="description" content="Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments">
<title>Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data | Andrew Heiss – Andrew Heiss</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../../">
<link href="../../../../..//files/favicon-512.png" rel="icon" type="image/png">
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting-17c909d5fd25ae21b861c0c7a49b2096.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap-5cd0811f461c8271ae6bab49df9501be.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script src="../../../../../site_libs/quarto-contrib/iconify-2.0.0/iconify-icon.min.js"></script><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-527449-5', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script><style>

      .quarto-title-block .quarto-title-banner {
        background: #170C3A;
      }
</style>
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
<meta property="og:title" content="Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data | Andrew Heiss">
<meta property="og:description" content="Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments">
<meta property="og:image" content="https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/blackwell-glynn-fig-2.png">
<meta property="og:site_name" content="Andrew Heiss">
<meta property="og:locale" content="en_US">
<meta property="og:image:height" content="520">
<meta property="og:image:width" content="1704">
<meta name="twitter:title" content="Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data | Andrew Heiss">
<meta name="twitter:description" content="Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments">
<meta name="twitter:image" content="https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/blackwell-glynn-fig-2.png">
<meta name="twitter:creator" content="@andrewheiss">
<meta name="twitter:site" content="@andrewheiss">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="520">
<meta name="twitter:image-width" content="1704">
</head>
<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">Andrew Heiss</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
<li class="nav-item">
    <a class="nav-link" href="../../../../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../cv/index.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../research/index.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../teaching/index.html"> 
<span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../talks/index.html"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../now/index.html"> 
<span class="menu-text">Now</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../uses/index.html"> 
<span class="menu-text">Uses</span></a>
  </li>  
</ul>
<ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
    <a class="nav-link" href="../../../../../atom.xml"> 
<span class="menu-text"><iconify-icon inline="" icon="bi:rss" style="font-size: 1.1em;" aria-label="Icon rss from bi Iconify.design set." title="RSS"></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="mailto:aheiss@gsu.edu"> 
<span class="menu-text"><iconify-icon inline="" icon="bi:envelope" style="font-size: 1.1em;" aria-label="Icon envelope from bi Iconify.design set." title="E-mail"></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://bsky.app/profile/andrew.heiss.phd" rel="me"> 
<span class="menu-text"><iconify-icon inline="" icon="fa6-brands:bluesky" style="font-size: 1.1em;" aria-label="Icon bluesky from fa6-brands Iconify.design set." title="Bluesky"></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://fediscience.org/users/andrew/" rel="me"> 
<span class="menu-text"><iconify-icon inline="" icon="bi:mastodon" style="font-size: 1.1em;" aria-label="Icon mastodon from bi Iconify.design set." title="Mastodon"></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/andrewheiss" rel="me"> 
<span class="menu-text"><iconify-icon inline="" icon="bi:github" style="font-size: 1.1em;" aria-label="Icon github from bi Iconify.design set." title="GitHub"></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.youtube.com/andrewheiss" rel="me"> 
<span class="menu-text"><iconify-icon inline="" icon="bi:youtube" style="font-size: 1.1em;" aria-label="Icon youtube from bi Iconify.design set." title="YouTube"></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.heissatopia.com/"> 
<span class="menu-text"><iconify-icon inline="" icon="fa6-brands:blogger" style="font-size: 1.15em;" aria-label="Icon blogger from fa6-brands Iconify.design set." title="Blogger"></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/andrewheiss" rel="me"> 
<span class="menu-text"><iconify-icon inline="" icon="bi:linkedin" style="font-size: 1.1em;" aria-label="Icon linkedin from bi Iconify.design set." title="LinkedIn"></iconify-icon></span></a>
  </li>  
</ul>
</div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default blog-post page-columns page-full"><div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">r</div>
                <div class="quarto-category">tidyverse</div>
                <div class="quarto-category">causal inference</div>
                <div class="quarto-category">DAGs</div>
                <div class="quarto-category">do calculus</div>
                <div class="quarto-category">inverse probability weighting</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://www.andrewheiss.com/">Andrew Heiss</a> <a href="https://orcid.org/0000-0002-3948-3914" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Thursday, December 3, 2020</p>
      </div>
    </div>
    
      
      <div>
      <div class="quarto-title-meta-heading">Doi</div>
      <div class="quarto-title-meta-contents">
        <p class="doi">
          <a href="https://doi.org/10.59350/48w1z-xen07">10.59350/48w1z-xen07</a>
        </p>
      </div>
    </div>
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Contents</h2>
   
  <ul>
<li><a href="#dags-and-time-series-cross-sectional-tscs-data" id="toc-dags-and-time-series-cross-sectional-tscs-data" class="nav-link active" data-scroll-target="#dags-and-time-series-cross-sectional-tscs-data">DAGs and time-series cross-sectional (TSCS) data</a></li>
  <li><a href="#marginal-structural-models" id="toc-marginal-structural-models" class="nav-link" data-scroll-target="#marginal-structural-models">Marginal structural models</a></li>
  <li><a href="#simulated-time-series-cross-sectional-data" id="toc-simulated-time-series-cross-sectional-data" class="nav-link" data-scroll-target="#simulated-time-series-cross-sectional-data">Simulated time-series cross-sectional data</a></li>
  <li>
<a href="#marginal-structural-model-with-a-binary-treatment" id="toc-marginal-structural-model-with-a-binary-treatment" class="nav-link" data-scroll-target="#marginal-structural-model-with-a-binary-treatment">Marginal structural model with a binary treatment</a>
  <ul class="collapse">
<li><a href="#naive-estimate-without-weights" id="toc-naive-estimate-without-weights" class="nav-link" data-scroll-target="#naive-estimate-without-weights">Naive estimate without weights</a></li>
  <li><a href="#manual-weights" id="toc-manual-weights" class="nav-link" data-scroll-target="#manual-weights">Manual weights</a></li>
  <li><a href="#weights-with-the-ipw-package" id="toc-weights-with-the-ipw-package" class="nav-link" data-scroll-target="#weights-with-the-ipw-package">Weights with the <strong>ipw</strong> package</a></li>
  </ul>
</li>
  <li>
<a href="#marginal-structural-model-with-a-continuous-treatment" id="toc-marginal-structural-model-with-a-continuous-treatment" class="nav-link" data-scroll-target="#marginal-structural-model-with-a-continuous-treatment">Marginal structural model with a continuous treatment</a>
  <ul class="collapse">
<li><a href="#naive-estimate-without-weights-1" id="toc-naive-estimate-without-weights-1" class="nav-link" data-scroll-target="#naive-estimate-without-weights-1">Naive estimate without weights</a></li>
  <li><a href="#manual-weights-1" id="toc-manual-weights-1" class="nav-link" data-scroll-target="#manual-weights-1">Manual weights</a></li>
  <li><a href="#weights-with-the-ipw-package-1" id="toc-weights-with-the-ipw-package-1" class="nav-link" data-scroll-target="#weights-with-the-ipw-package-1">Weights with the <strong>ipw</strong> package</a></li>
  </ul>
</li>
  <li><a href="#important-caveats" id="toc-important-caveats" class="nav-link" data-scroll-target="#important-caveats">Important caveats!</a></li>
  </ul></nav>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content"><p>In <a href="../../../../../blog/2020/12/01/ipw-binary-continuous/">my post on generating inverse probability weights for both binary and continuous treatments</a>, I mentioned that I’d eventually need to figure out how to deal with more complex data structures and causal models where treatments, outcomes, and confounders vary over time. Instead of adjusting for DAG confounding with inverse probability weights, we need to use something called marginal structural models (MSMs) to make adjustments that account for treatment and outcome history and other time structures. This is complex stuff and social science hasn’t done much with it (but it’s been a common approach in epidemiology).</p>
<p>This post is my first attempt at teaching myself how to do this stuff. As I note at the end in the <a href="#important-caveats">caveats section</a>, there might be (surely are!) mistakes. Please correct them!</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span>  <span class="co"># For mixed models</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://lrberge.github.io/fixest/">fixest</a></span><span class="op">)</span>  <span class="co"># For fixed effects models</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://broom.tidymodels.org/">broom</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bbolker/broom.mixed">broom.mixed</a></span><span class="op">)</span>  <span class="co"># For tidying mixed models</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/r-causal/ggdag">ggdag</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.dagitty.net">dagitty</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ipw</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="dags-and-time-series-cross-sectional-tscs-data" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="dags-and-time-series-cross-sectional-tscs-data">DAGs and time-series cross-sectional (TSCS) data</h2>
<p>Let’s pretend that we’re interested in the causal effect of a policy in a country on a country’s happiness. We’ll work with two different policies: whether a country implements a 6-hour workday (like <a href="https://www.forbes.com/sites/jackkelly/2020/01/08/finlands-prime-ministers-aspirational-goal-of-a-six-hour-four-day-workweek-will-this-ever-happen/?sh=79367a836384">Finland has been considering</a>), which is binary, and the number of mandated vacation days a country provides, which is continuous. Both the policy and national happiness are influenced and confounded by a few different variables: general country-specific trends, GDP per capita, level of democratization, and level of political corruption.</p>
<p>In the absence of time, this causal model is fairly straightforward:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simple_dag</span> <span class="op">&lt;-</span> <span class="fu">dagify</span><span class="op">(</span><span class="va">happiness</span> <span class="op">~</span> <span class="va">policy</span> <span class="op">+</span> <span class="va">gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> <span class="va">corruption</span> <span class="op">+</span> <span class="va">country</span>,</span>
<span>                     <span class="va">policy</span> <span class="op">~</span> <span class="va">gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> <span class="va">corruption</span> <span class="op">+</span> <span class="va">country</span>,</span>
<span>                     coords <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>policy <span class="op">=</span> <span class="fl">1</span>, happiness <span class="op">=</span> <span class="fl">5</span>, gdp_cap <span class="op">=</span> <span class="fl">2</span>, </span>
<span>                                         democracy <span class="op">=</span> <span class="fl">3</span>, corruption <span class="op">=</span> <span class="fl">4</span>, country <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>                                   y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>policy <span class="op">=</span> <span class="fl">2</span>, happiness <span class="op">=</span> <span class="fl">2</span>, gdp_cap <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                                         democracy <span class="op">=</span> <span class="fl">3.3</span>, corruption <span class="op">=</span> <span class="fl">3</span>, country <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                     exposure <span class="op">=</span> <span class="st">"policy"</span>,</span>
<span>                     outcome <span class="op">=</span> <span class="st">"happiness"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggdag_status</span><span class="op">(</span><span class="va">simple_dag</span>, text_col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">guides</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_dag</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="index_files/figure-html/dag-simple-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p>In a regular DAG setting, we can isolate the arrow between policy and happiness by statistically adjusting for all the nodes that open up backdoor relationships between them, or confound them. We can use <em>do</em>-calculus logic for that, or we can use R:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">adjustmentSets</span><span class="op">(</span><span class="va">simple_dag</span><span class="op">)</span></span>
<span><span class="co">## { corruption, country, democracy, gdp_cap }</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Adjusting for the four confounders here is thus sufficient for closing all the backdoors and isolating the causal effect of the policy on national happiness. A standard approach to this kind of adjustment is inverse probability weighting, and I have <a href="../../../../../blog/2020/12/01/ipw-binary-continuous/">a whole post about how to do that with both binary and continuous treatments</a> (as well as <a href="../../../../../blog/2020/02/25/closing-backdoors-dags/">another post</a> and <a href="../../../../../research/chapters/heiss-causal-inference-2021/">a textbook chapter</a> with even more details and examples).</p>
<p>However, in reality, time also influences policies, happiness, and other confounders. The number of vacation days a country offers in 2019 depends a lot on the number of vacation days offered in 2018, and 2017, and 2016, and so on. Also, a country’s GDP, level of democracy, and level of corruption all depend on earlier values. Countries aren’t just getting random levels of democracy each year! Not all confounders vary with time—country remains the same every year, as do things like region and continent.</p>
<p>On top of all that, happiness in a previous year could influence the policy in the current year. If a country has lower aggregate happiness in 2016, that could influences politicians’ choice to mandate a 6-hour workday or increase vacation days in 2017 or 2018.</p>
<p>We need to incorporate time into our simple DAG. Because we’re adding a bunch more nodes, I’m going to collapse the time-varying confounders (GDP per capita, democracy, and corruption) and time-invariant confounders (just country here) into single separate nodes. To account for time, I add <span class="math inline">\(t\)</span> subscripts: <span class="math inline">\(t\)</span> represents the current year, <span class="math inline">\(t - 1\)</span> (<code>t_m1</code> in the graph) represents the previous year, <span class="math inline">\(t - 2\)</span> represents two years earlier, and so on.</p>
<p>Here’s what this looks like:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">time_dag</span> <span class="op">&lt;-</span> <span class="fu">dagify</span><span class="op">(</span><span class="va">happiness_t</span> <span class="op">~</span> <span class="va">policy_t</span> <span class="op">+</span> <span class="va">varying_confounders_t</span> <span class="op">+</span> <span class="va">happiness_tm1</span> <span class="op">+</span> <span class="va">nonvarying_confounders</span>,</span>
<span>                   <span class="va">policy_t</span> <span class="op">~</span> <span class="va">varying_confounders_t</span> <span class="op">+</span> <span class="va">happiness_tm1</span> <span class="op">+</span> <span class="va">policy_tm1</span> <span class="op">+</span> <span class="va">nonvarying_confounders</span>,</span>
<span>                   <span class="va">varying_confounders_t</span> <span class="op">~</span> <span class="va">happiness_tm1</span> <span class="op">+</span> <span class="va">varying_confounders_tm1</span> <span class="op">+</span> <span class="va">nonvarying_confounders</span>,</span>
<span>                   <span class="va">happiness_tm1</span> <span class="op">~</span> <span class="va">policy_tm1</span> <span class="op">+</span> <span class="va">varying_confounders_tm1</span> <span class="op">+</span> <span class="va">nonvarying_confounders</span>,</span>
<span>                   <span class="va">policy_tm1</span> <span class="op">~</span> <span class="va">varying_confounders_tm1</span> <span class="op">+</span> <span class="va">nonvarying_confounders</span>,</span>
<span>                   <span class="va">varying_confounders_tm1</span> <span class="op">~</span> <span class="va">nonvarying_confounders</span>,</span>
<span>                   coords <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>happiness_t <span class="op">=</span> <span class="fl">4</span>, policy_t <span class="op">=</span> <span class="fl">3</span>, varying_confounders_t <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                                       happiness_tm1 <span class="op">=</span> <span class="fl">2</span>, policy_tm1 <span class="op">=</span> <span class="fl">1</span>, varying_confounders_tm1 <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                                       nonvarying_confounders <span class="op">=</span> <span class="fl">2.5</span><span class="op">)</span>,</span>
<span>                                 y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>happiness_t <span class="op">=</span> <span class="fl">3</span>, policy_t <span class="op">=</span> <span class="fl">2</span>, varying_confounders_t <span class="op">=</span> <span class="fl">4</span>, </span>
<span>                                       happiness_tm1 <span class="op">=</span> <span class="fl">3</span>, policy_tm1 <span class="op">=</span> <span class="fl">2</span>, varying_confounders_tm1 <span class="op">=</span> <span class="fl">4</span>,</span>
<span>                                       nonvarying_confounders <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                   exposure <span class="op">=</span> <span class="st">"policy_t"</span>,</span>
<span>                   outcome <span class="op">=</span> <span class="st">"happiness_t"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggdag_status</span><span class="op">(</span><span class="va">time_dag</span>, text_col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">guides</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_dag</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="index_files/figure-html/dag-complex-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Phew. That’s bananas. And that’s just for one time period. Technically there are also nodes from <span class="math inline">\(t - 2\)</span> and <span class="math inline">\(t - 3\)</span> and so on that influence <span class="math inline">\(t - 1\)</span>. Figure 2 from <span class="citation" data-cites="BlackwellGlynn:2018">Blackwell and Glynn (<a href="#ref-BlackwellGlynn:2018" role="doc-biblioref">2018</a>)</span> shows a similar structure with previous time periods (though they don’t have an arrow from <span class="math inline">\(Y_{t-1}\)</span> to <span class="math inline">\(Y\)</span>):</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><p><img src="blackwell-glynn-fig-2.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Figure 2 from <span class="citation" data-cites="BlackwellGlynn:2018">Blackwell and Glynn (<a href="#ref-BlackwellGlynn:2018" role="doc-biblioref">2018</a>)</span></figcaption></figure>
</div>
<p>All we care about in this situation is the single arrow between <code>policy_t</code> and <code>happiness_t</code>. (There are ways of looking at other arrows, like the effect of <code>policy_tm1</code> on <code>happiness_t</code>, but we won’t try to measure those here. <span class="citation" data-cites="BlackwellGlynn:2018">Blackwell and Glynn (<a href="#ref-BlackwellGlynn:2018" role="doc-biblioref">2018</a>)</span> show how to do that.)</p>
<p>We can use <em>do</em>-calculus logic to see what nodes need to be adjusted for to isolate that arrow:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">adjustmentSets</span><span class="op">(</span><span class="va">time_dag</span><span class="op">)</span></span>
<span><span class="co">## { happiness_tm1, nonvarying_confounders, varying_confounders_t }</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>According to this, we should adjust for time variant confounders in the current year, happiness in the previous year, and nonvarying confounders like country. <em>However</em>, this won’t be completely accurate because the previous history matters. In general, situations where treatments, confounders, and outcomes vary over time, adjustment approaches like inverse probability weighting will be biased and incorrect.</p>
</section><section id="marginal-structural-models" class="level2"><h2 class="anchored" data-anchor-id="marginal-structural-models">Marginal structural models</h2>
<p>To account for this time structure, we can instead use something called marginal structural models (MSMs) to make DAG adjustments. These have been used widely in epidemiology, and there are some really great and accessible overviews of the method here:</p>
<ul>
<li>Chapter 12 in <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">Miguel A. Hernán and James M. Robins, <em>Causal Inference: What If</em></a> <span class="citation" data-cites="HernanRobins:2020">(<a href="#ref-HernanRobins:2020" role="doc-biblioref">Hernán and Robins 2020</a>)</span>
</li>
<li>Felix Thoemmes and Anthony D. Ong, “A Primer on Inverse Probability of Treatment Weighting and Marginal Structural Models” <span class="citation" data-cites="ThoemmesOng:2016">(<a href="#ref-ThoemmesOng:2016" role="doc-biblioref">Thoemmes and Ong 2016</a>)</span>
</li>
<li>Stephen R. Cole and Miguel A. Hernán, “Constructing Inverse Probability Weights for Marginal Structural Models” <span class="citation" data-cites="ColeHernan:2008">(<a href="#ref-ColeHernan:2008" role="doc-biblioref">Cole and Hernán 2008</a>)</span>
</li>
<li>Kosuke Imai and Marc Ratkovic, “Robust Estimation of Inverse Probability Weights for Marginal Structural Models” <span class="citation" data-cites="ImaiRatkovic:2015">(<a href="#ref-ImaiRatkovic:2015" role="doc-biblioref">Imai and Ratkovic 2015</a>)</span>
</li>
<li>James M. Robins, Miguel Ángel Hernán, and Babette Brumback, “Marginal Structural Models and Causal Inference in Epidemiology” <span class="citation" data-cites="RobinsHernanBrumback:2000">(<a href="#ref-RobinsHernanBrumback:2000" role="doc-biblioref">Robins, Hernán, and Brumback 2000</a>)</span>
</li>
</ul>
<p>In my world of public policy and political science, though, MSMs are far rarer, even though <strong><em>tons of the data we use</em></strong> is time-series cross-sectional (TSCS) data, or panel data where each row represents a country and year (e.g.&nbsp;row 1 is Afghanistan in 2008, row 2 is Afghanistan in 2009, etc.) or state and year (e.g.&nbsp;Alabama 2015, Alabama 2016, etc.). The only paper I’ve really seen that uses MSMs in the political science world is <span class="citation" data-cites="BlackwellGlynn:2018">Blackwell and Glynn (<a href="#ref-BlackwellGlynn:2018" role="doc-biblioref">2018</a>)</span>, which is an introduction to the topic and a call for using them more:</p>
<ul>
<li>Matthew Blackwell and Adam N. Glynn, “How to Make Causal Inferences with Time-Series Cross-Sectional Data under Selection on Observables,” <span class="citation" data-cites="BlackwellGlynn:2018">(<a href="#ref-BlackwellGlynn:2018" role="doc-biblioref">Blackwell and Glynn 2018</a>)</span>
</li>
</ul>
<p>The basic intuition behind MSMs is similar to <a href="blog/2020/12/01/ipw-binary-continuous/">simpler inverse probability weighting</a>:</p>
<ul>
<li>Calculate weights using confounders and the time structure</li>
<li>Calculate the average treatment effect using the weights and the time structure</li>
</ul>
<p>The formula for calculating weights differs depending on if the treatment is binary or continuous, and they’re written slightly differently across those different resources listed above.</p>
<p>Here’s my version of how to calculate stabilized inverse probability weights with a binary treatment:</p>
<p><span class="math display">\[
\text{Binary stabilized IPW}_{it} = \prod^t_{t = 1} \frac{P[X_{it} | \bar{X}_{i, t-1}, V_i]}{P[X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i]}
\]</span></p>
<p>There are a ton of variables in this equation. Let’s go through them one at a time:</p>
<ul>
<li>
<span class="math inline">\(i\)</span> stands for an individual (person, country, etc.)</li>
<li>
<span class="math inline">\(t\)</span> stands for a time period (year, month, day, etc.)</li>
<li>
<span class="math inline">\(X\)</span> stands for the observed treatment status; <span class="math inline">\(X_{it}\)</span> stands for the observed treatment status of an individual at a given time. This is often written more specifically as <span class="math inline">\(X_{it} = x_{it}\)</span> (see equation 1 in p.&nbsp;46 in <span class="citation" data-cites="ThoemmesOng:2016">Thoemmes and Ong (<a href="#ref-ThoemmesOng:2016" role="doc-biblioref">2016</a>)</span>, and <a href="https://rpubs.com/mbounthavong/IPTW_MSM_Tutorial">the equation at the beginning of this tutorial here</a>, for instance), but for simplicity I’ll just write it as <span class="math inline">\(X_{it}\)</span>.</li>
<li>
<span class="math inline">\(\bar{X}\)</span> stands for the individual’s history of treatment assignment (e.g.&nbsp;all <span class="math inline">\(X\)</span> values in previous time periods)</li>
<li>
<span class="math inline">\(Y\)</span> stands for the outcome; <span class="math inline">\(Y_{it}\)</span> stands for the outcome of an individual at a given time.</li>
<li>
<span class="math inline">\(C\)</span> stands for time <em>varying</em> confounders; because these change over time, <span class="math inline">\(C\)</span> gets a <span class="math inline">\(t\)</span> subscript: <span class="math inline">\(C_{it}\)</span>
</li>
<li>
<span class="math inline">\(V\)</span> stands for time <em>invarying</em> confounders; that’s why there’s no <span class="math inline">\(t\)</span> in <span class="math inline">\(V_i\)</span>
</li>
<li>Finally <span class="math inline">\(P[\cdot]\)</span> stands for the probability distribution</li>
</ul>
<p>Here’s a more human explanation:</p>
<ul>
<li>The numerator contains the probability of the observed treatment status (<span class="math inline">\(X\)</span>) at each time given the previous history of treatment (<span class="math inline">\(\bar{X}\)</span>) and time <em>invariant</em> confounders (<span class="math inline">\(V_i\)</span>)</li>
<li>The denominator contains the probability of the observed treatment status (<span class="math inline">\(X\)</span>) at each time given the previous history of treatment (<span class="math inline">\(\bar{X}\)</span>), previous outcomes (<span class="math inline">\(Y_{i, t-1}\)</span>), time <em>varying</em> confounders (<span class="math inline">\(C_{it}\)</span>) and time <em>invariant</em> confounders (<span class="math inline">\(V_i\)</span>). The previous outcomes part (<span class="math inline">\(Y_{i, t-1}\)</span>) is optional; if you think that the outcome’s previous values influence current values, and the DAG shows an arrow from <span class="math inline">\(Y_{t-1}\)</span> and <span class="math inline">\(Y_t\)</span>, include it.</li>
</ul>
<p>Importantly, time varying confounders (<span class="math inline">\(C_{it}\)</span>) are included in the denominator only, not the numerator. The lagged outcome (<span class="math inline">\(Y_{i, t-1}\)</span>), if used, also only goes in the denominator.</p>
<p>Technically the numerator can just be 1 instead of the whole <span class="math inline">\(P[\cdot]\)</span> thing, but that creates unstable weights. Using <span class="math inline">\(P[\cdot]\)</span> in the numerator creates stabilized weights.</p>
<p>The equation for continuous weights looks really similar:</p>
<p><span class="math display">\[
\text{Continuous stabilized IPW}_{it} = \prod^t_{t = 1} \frac{f_{X | \bar{X}, V}[(X_{it} | \bar{X}_{i, t-1}, V_i); \mu_1, \sigma^2_1]}{f_{X | \bar{X}, Y, C, V}[(X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i), \mu_2, \sigma^2_2]}
\]</span></p>
<p>Yikes. This is looks really complicated (and it is!), but again we can separate it into individual parts:</p>
<ul>
<li>
<span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, <span class="math inline">\(V\)</span>, <span class="math inline">\(C\)</span>, <span class="math inline">\(i\)</span>, and <span class="math inline">\(t\)</span> are all the same as the binary version of the formula</li>
<li>The numerator is still the treatment, treatment history, and time invariant confounders</li>
<li>The denominator is still the treatment, treatment history, previous outcome, time varying confounders, and time invariant confounders</li>
<li>The <span class="math inline">\(f_{\cdot}(\cdot)\)</span> functions are new and stand for a probability density function with a mean of <span class="math inline">\(\mu\)</span> and a variance of <span class="math inline">\(\sigma^2\)</span>
</li>
</ul>
<p>That’s a ton of information and it’s all really abstract. Let’s try this out with some simulated data</p>
</section><section id="simulated-time-series-cross-sectional-data" class="level2"><h2 class="anchored" data-anchor-id="simulated-time-series-cross-sectional-data">Simulated time-series cross-sectional data</h2>
<p>For this example, we’ll use some data I generated with the <strong>fabricatr</strong> package, which makes it really easy to build multilevel and nested structures like country- and year-level variables. The actual code to generate this is a little long, mostly because it’s heavily annotated and has a ton of intermediate variables. You can download the data here if you want to follow along with the rest of the code:</p>
<ul>
<li><a href="happiness_data.csv"><i class="fas fa-file-csv"></i> <code>happiness_data.csv</code></a></li>
<li><a href="happiness_simulation.R"><i class="fab fa-r-project"></i> <code>happiness_simulation.R</code></a></li>
</ul>
<p>It contains a bunch of different columns:</p>
<ul>
<li>
<code>country</code>: The country name (generated as a pronouncable 5-letter sequence (<a href="https://arxiv.org/html/0901.4016">proquint</a>) with the <a href="https://reside-ic.github.io/ids/"><strong>ids</strong> package</a>)</li>
<li>
<code>year</code>: The year</li>
<li>
<code>vacation_days</code>: The number of mandated vacation days. This is a treatment variable.</li>
<li>
<code>policy</code>: An indicator for whether a country has passed a policy that mandates a 6-hour workday. This is another treatment variable</li>
<li>
<code>happiness_vacation</code>: The level of happiness in a country, on a scale of 1–100 (more happiness = higher values). This is the outcome when using <code>vacation_days</code> as the treatment.</li>
<li>
<code>happiness_policy</code>: The level of happiness in a country. This is the outcome when using <code>policy</code> as the treatment.</li>
<li>
<code>log_populuation</code>: Logged population</li>
<li>
<code>log_gdp</code>: Logged GDP</li>
<li>
<code>gdp</code>: GDP</li>
<li>
<code>population</code>: Population</li>
<li>
<code>gdp_cap</code>: GDP per capita</li>
<li>
<code>log_gdp_cap</code>: Logged GDP per capita</li>
<li>
<code>democracy</code>: The country’s level of democracy, on a scale of 1–100 (more democratic = higher values)</li>
<li>
<code>corruption</code>: The level of political corruption in a country, on a scale of 1–100 (more corrupt = higher values)</li>
<li>
<code>lag_*</code>: Lagged versions of a bunch of different columns</li>
</ul>
<p>And here’s what the actual data looks like:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">happiness_data</span> <span class="op">&lt;-</span> <span class="fu">read_csv</span><span class="op">(</span><span class="st">"happiness_data.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">happiness_data</span><span class="op">)</span></span>
<span><span class="co">## Rows: 1,520</span></span>
<span><span class="co">## Columns: 18</span></span>
<span><span class="co">## $ country                &lt;chr&gt; "Mimim", "Mimim", "Mimim", "Mimim", "Mimim", "Mimim", "Mi…</span></span>
<span><span class="co">## $ year                   &lt;dbl&gt; 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 201…</span></span>
<span><span class="co">## $ vacation_days          &lt;dbl&gt; 12, 14, 16, 17, 18, 20, 21, 22, 24, 25, 9, 11, 13, 14, 16…</span></span>
<span><span class="co">## $ policy                 &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, …</span></span>
<span><span class="co">## $ happiness_vacation     &lt;dbl&gt; 43.2, 45.1, 52.7, 52.7, 53.5, 61.4, 63.1, 66.1, 71.4, 73.…</span></span>
<span><span class="co">## $ happiness_policy       &lt;dbl&gt; 36.9, 40.6, 44.3, 46.3, 54.3, 58.4, 54.7, 59.1, 67.6, 59.…</span></span>
<span><span class="co">## $ log_population         &lt;dbl&gt; 17.4, 17.4, 17.5, 17.5, 17.6, 17.6, 17.7, 17.7, 17.8, 17.…</span></span>
<span><span class="co">## $ log_gdp                &lt;dbl&gt; 23.1, 23.2, 23.3, 23.4, 23.5, 23.6, 23.7, 23.8, 23.9, 24.…</span></span>
<span><span class="co">## $ gdp                    &lt;dbl&gt; 1.06e+10, 1.18e+10, 1.27e+10, 1.48e+10, 1.57e+10, 1.78e+1…</span></span>
<span><span class="co">## $ population             &lt;dbl&gt; 36049651, 37745007, 39520093, 41378659, 43324629, 4536211…</span></span>
<span><span class="co">## $ gdp_cap                &lt;dbl&gt; 293, 313, 321, 358, 361, 392, 434, 446, 483, 528, 5750, 6…</span></span>
<span><span class="co">## $ log_gdp_cap            &lt;dbl&gt; 5.68, 5.74, 5.77, 5.88, 5.89, 5.97, 6.07, 6.10, 6.18, 6.2…</span></span>
<span><span class="co">## $ democracy              &lt;dbl&gt; 56.9, 59.8, 77.5, 71.0, 76.2, 83.1, 87.3, 92.2, 100.0, 99…</span></span>
<span><span class="co">## $ corruption             &lt;dbl&gt; 63.4, 62.9, 62.0, 60.7, 61.9, 60.4, 60.4, 57.9, 58.0, 58.…</span></span>
<span><span class="co">## $ lag_policy             &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, …</span></span>
<span><span class="co">## $ lag_happiness_policy   &lt;dbl&gt; 36.8, 36.9, 40.6, 44.3, 46.3, 54.3, 58.4, 54.7, 59.1, 67.…</span></span>
<span><span class="co">## $ lag_vacation_days      &lt;dbl&gt; 12, 12, 14, 16, 17, 18, 20, 21, 22, 24, 9, 9, 11, 13, 14,…</span></span>
<span><span class="co">## $ lag_happiness_vacation &lt;dbl&gt; 41.5, 43.2, 45.1, 52.7, 52.7, 53.5, 61.4, 63.1, 66.1, 71.…</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll use this data explore two different questions:</p>
<ol type="1">
<li><strong>Binary treatment: What is the effect of a 6-hour workday policy on national happiness?</strong></li>
<li><strong>Continuous treatment: What is the effect of the number of mandated vacation days on national happiness?</strong></li>
</ol></section><section id="marginal-structural-model-with-a-binary-treatment" class="level2"><h2 class="anchored" data-anchor-id="marginal-structural-model-with-a-binary-treatment">Marginal structural model with a binary treatment</h2>
<p>Before we do anything with the binary treatment, we need to filter the data a little. Because of the nature of the data, some of the fake countries never implement the policy and have all 0s in the <code>policy</code> column. Weird things happen with the math of logistic regression if there are countries that have all 0s or all 1s for the outcome, since it’s technically impossible to predict their outcomes. That’s why <a href="https://vuorre.netlify.app/post/2019/02/18/analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/">zero-one inflated beta (ZOIB) models or hurdle models</a> are a thing—they’re two step models that first model if you do the policy at all, then model the probability of the policy if it does happen. Rather than deal with ZOIB stuff here, I made it so that all countries start with 0 for the policy (i.e.&nbsp;no country has the policy in the first year), and then here we filter out any countries that don’t ever implement the policy.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">happiness_binary</span> <span class="op">&lt;-</span> <span class="va">happiness_data</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">country</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>never_policy <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/all.html">all</a></span><span class="op">(</span><span class="va">policy</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ungroup</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="op">!</span><span class="va">never_policy</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="naive-estimate-without-weights" class="level3"><h3 class="anchored" data-anchor-id="naive-estimate-without-weights">Naive estimate without weights</h3>
<p>Before playing with MSMs, let’s look at what the effect of the policy is on happiness without doing any inverse probability weighting for DAG adjustment. This is what most political science and international relations and public policy papers do. This is what I did in my dissertation and what I’ve done in a bunch of working papers. The wrongness of this approach is why I’m writing this post :)</p>
<p>This is just a regular linear regression model. I could run it with <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>, but then a ton of country and year coefficients would be included by default in the results, so I use <code>feols()</code> from the delightful <strong>fixest</strong> package to include country and year as fixed effects. The results from <code>feols()</code> and <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> are identical here; <code>feols()</code> is cleaner and faster.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_naive</span> <span class="op">&lt;-</span> <span class="fu">feols</span><span class="op">(</span><span class="va">happiness_policy</span> <span class="op">~</span> <span class="va">policy</span> <span class="op">+</span> <span class="va">log_gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> </span>
<span>                       <span class="va">corruption</span> <span class="op">+</span> <span class="va">lag_happiness_policy</span> <span class="op">+</span> <span class="va">lag_policy</span> <span class="op">|</span> <span class="va">country</span> <span class="op">+</span> <span class="va">year</span>,</span>
<span>                data <span class="op">=</span> <span class="va">happiness_binary</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">model_naive</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 6 × 5</span></span>
<span><span class="co">##   term                 estimate std.error statistic  p.value</span></span>
<span><span class="co">##   &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span><span class="co">## 1 policy                  6.76     0.397      17.0  1.36e-35</span></span>
<span><span class="co">## 2 log_gdp_cap             3.80     1.85        2.05 4.24e- 2</span></span>
<span><span class="co">## 3 democracy               0.146    0.0218      6.71 4.78e-10</span></span>
<span><span class="co">## 4 corruption             -0.158    0.0252     -6.26 4.62e- 9</span></span>
<span><span class="co">## 5 lag_happiness_policy    0.172    0.0449      3.82 2.02e- 4</span></span>
<span><span class="co">## 6 lag_policy             -1.54     0.511      -3.01 3.11e- 3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>According to this, implementing a 6-hour workday is associated with a 6.8-point increase in national happiness. This is wrong though! We need to generate and use time-adjusted inverse probability weights to adjust for these confounders.</p>
</section><section id="manual-weights" class="level3"><h3 class="anchored" data-anchor-id="manual-weights">Manual weights</h3>
<p>We’ll follow this formula to use confounders and previous treatments and outcomes to generate stabilized weights:</p>
<p><span class="math display">\[
\text{Binary stabilized IPW}_{it} = \prod^t_{t = 1} \frac{P[X_{it} | \bar{X}_{i, t-1}, V_i]}{P[X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i]}
\]</span></p>
<p>The numerator predicts the treatment using the previous treatment and time invariant confounders. We’ll use logistic regression here, but I’m like 90% sure you can do fancier things like multilevel models or machine learning or Bayes stuff:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_num</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">policy</span> <span class="op">~</span> <span class="va">lag_policy</span> <span class="op">+</span> <span class="va">country</span>, </span>
<span>                 data <span class="op">=</span> <span class="va">happiness_binary</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The denominator predicts the treatment using time-varying confounders, previous outcome, previous treatment, and time invariant confounders. Again we’ll use logistic regression here, but you can probably do fancier stuff too:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># There's a warning that fitted probabiltiies of 0 or 1 occurred, likely because</span></span>
<span><span class="co"># my data is too perfect. Oh well---we'll live with it.</span></span>
<span><span class="va">model_denom</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">policy</span> <span class="op">~</span> <span class="va">log_gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> <span class="va">corruption</span> <span class="op">+</span> </span>
<span>                     <span class="va">lag_happiness_policy</span> <span class="op">+</span> <span class="va">lag_policy</span> <span class="op">+</span> <span class="va">country</span>, </span>
<span>                   data <span class="op">=</span> <span class="va">happiness_binary</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This also works if you use fixest::feglm() for country fixed effects</span></span>
<span><span class="co"># model_denom &lt;- feglm(policy ~ log_gdp_cap + democracy + corruption +</span></span>
<span><span class="co">#                        lag_happiness_policy + lag_policy | country,</span></span>
<span><span class="co">#                      data = happiness_binary, family = binomial(link = "logit"))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally we need to use the results from the numerator and denominator to construct the weights following the equation:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">happiness_binary_weights</span> <span class="op">&lt;-</span> <span class="va">happiness_binary</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="co"># Propensity scores from the models</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>propensity_num <span class="op">=</span> <span class="va">model_num</span><span class="op">$</span><span class="va">fitted.values</span>,</span>
<span>         propensity_denom <span class="op">=</span> <span class="va">model_denom</span><span class="op">$</span><span class="va">fitted.values</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="co"># Probability of observed outcome</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>propensity_num_outcome <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">policy</span> <span class="op">==</span> <span class="fl">1</span>, <span class="va">propensity_num</span>, <span class="fl">1</span> <span class="op">-</span> <span class="va">propensity_num</span><span class="op">)</span>,</span>
<span>         propensity_denom_outcome <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">policy</span> <span class="op">==</span> <span class="fl">1</span>, <span class="va">propensity_denom</span>, <span class="fl">1</span> <span class="op">-</span> <span class="va">propensity_denom</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="co"># Numerator / denominator</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>weights_no_time <span class="op">=</span> <span class="va">propensity_num_outcome</span> <span class="op">/</span> <span class="va">propensity_denom_outcome</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="co"># Calculate the cumulative product of the weights within each country</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">country</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>ipw <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cumsum.html">cumprod</a></span><span class="op">(</span><span class="va">weights_no_time</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ungroup</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">happiness_binary_weights</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">country</span>, <span class="va">year</span>, <span class="va">policy</span>, <span class="va">happiness_policy</span>, <span class="va">ipw</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 6 × 5</span></span>
<span><span class="co">##   country  year policy happiness_policy   ipw</span></span>
<span><span class="co">##   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span><span class="co">## 1 Mimim    2010      0             36.9 0.800</span></span>
<span><span class="co">## 2 Mimim    2011      0             40.6 0.640</span></span>
<span><span class="co">## 3 Mimim    2012      0             44.3 0.516</span></span>
<span><span class="co">## 4 Mimim    2013      0             46.3 0.486</span></span>
<span><span class="co">## 5 Mimim    2014      1             54.3 0.116</span></span>
<span><span class="co">## 6 Mimim    2015      1             58.4 0.116</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally we’ll use those weights in a regression model to estimate the average treatment effect (ATE) of the policy on happiness. We need to use a model that accounts for the year and country panel structure for this. In every tutorial I’ve seen online, people use <code>geeglm()</code> from the <a href="https://cran.r-project.org/package=geepack"><strong>geepack</strong> package</a>, which lets you specify country and year dimensions in generalized estimating equations. These feel an awful lot like mixed models with random country/year effects. There’s some useful discussion and useful links about the differences between GEE models and multilevel models <a href="https://twitter.com/andrewheiss/status/1317634713935380480">in this Twitter thread here</a>. For the sake of this example, I’ll use multilevel models since I’m more familiar with them, and because you can build Bayesian ones with the <a href="https://paul-buerkner.github.io/brms/"><strong>brms</strong> package</a>; I have yet to find a Bayesian flavor of GEEs.</p>
<p>In the outcome model, we include the previous treatment history and the invariant confounders (<code>country</code>, which I include as a random effect). To account for the time structure in the data, I also include a year random effect.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_ate_binary</span> <span class="op">&lt;-</span> <span class="fu">lmer</span><span class="op">(</span><span class="va">happiness_policy</span> <span class="op">~</span> <span class="va">policy</span> <span class="op">+</span> <span class="va">lag_policy</span> <span class="op">+</span> </span>
<span>                           <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">country</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">year</span><span class="op">)</span>, </span>
<span>                  data <span class="op">=</span> <span class="va">happiness_binary_weights</span>, weights <span class="op">=</span> <span class="va">ipw</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">model_ate_binary</span>, effects <span class="op">=</span> <span class="st">"fixed"</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 3 × 5</span></span>
<span><span class="co">##   effect term        estimate std.error statistic</span></span>
<span><span class="co">##   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span><span class="co">## 1 fixed  (Intercept)    51.9      1.26      41.2 </span></span>
<span><span class="co">## 2 fixed  policy          7.64     0.510     15.0 </span></span>
<span><span class="co">## 3 fixed  lag_policy     -1.30     0.448     -2.91</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Voila! After adjusting for time-varying confounders and previous treatment history, the 6-hour workday policy <em>causes</em> an increase of 7.6 happiness points, on average. This is actually the effect that I built into the data. It worked!</p>
<p>However, I’m still not 100% confident that it did work. There are a lot of different moving parts here, and I’m not sure I have the right covariates in the right place (like in the outcome model, I’m fairly certain the model should be <code>happiness_policy ~ policy + lag_policy</code>, but I’m not sure).</p>
<p>Also the standard errors in this outcome model are wrong and have to be adjusted, either with fancy math or with bootstrapping (<span class="citation" data-cites="BlackwellGlynn:2018">Blackwell and Glynn (<a href="#ref-BlackwellGlynn:2018" role="doc-biblioref">2018</a>)</span> use boostrapping).</p>
<p>But still, this is really neat.</p>
</section><section id="weights-with-the-ipw-package" class="level3"><h3 class="anchored" data-anchor-id="weights-with-the-ipw-package">Weights with the <strong>ipw</strong> package</h3>
<p>Instead of manually doing all the math to generate the weights, we can use the <code>ipwtm()</code> function from the <a href="https://cran.r-project.org/package=ipw"><strong>ipw</strong> package</a> to do it for us. We still specify a numerator and denominator, but the function takes care of the rest of the math. The numbers are the same.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># ipwtm() can't handle tibbles! Force the data to be a data.frame</span></span>
<span><span class="va">weights_binary_ipw</span> <span class="op">&lt;-</span> <span class="fu">ipwtm</span><span class="op">(</span></span>
<span>  exposure <span class="op">=</span> <span class="va">policy</span>,</span>
<span>  family <span class="op">=</span> <span class="st">"binomial"</span>,</span>
<span>  link <span class="op">=</span> <span class="st">"logit"</span>,</span>
<span>  <span class="co"># Time invariant stuff</span></span>
<span>  numerator <span class="op">=</span> <span class="op">~</span> <span class="va">lag_policy</span> <span class="op">+</span> <span class="va">country</span>,</span>
<span>  <span class="co"># All confounders</span></span>
<span>  denominator <span class="op">=</span> <span class="op">~</span> <span class="va">log_gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> <span class="va">corruption</span> <span class="op">+</span> </span>
<span>    <span class="va">lag_happiness_policy</span> <span class="op">+</span> <span class="va">lag_policy</span> <span class="op">+</span> <span class="va">country</span>,</span>
<span>  id <span class="op">=</span> <span class="va">country</span>,</span>
<span>  timevar <span class="op">=</span> <span class="va">year</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"all"</span>,</span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">happiness_binary</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># They're the same!</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">weights_binary_ipw</span><span class="op">$</span><span class="va">ipw.weights</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.800 0.640 0.516 0.486 0.116 0.116</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">happiness_binary_weights</span><span class="op">$</span><span class="va">ipw</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.800 0.640 0.516 0.486 0.116 0.116</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This <code>weights_binary_ipw</code> object contains a bunch of other information too, but all we really care about here is what’s in the <code>ipw.weights</code> slot. We can add those weights as a column in a dataset and run the outcome model, which will give us the same ATE as before (unsurprisingly, since they’re identical). Technically we don’t need to add a new column with the weights—the model will work if they’re a standalone vector—but I don’t like mixing data frames and standalone vectors and prefer to keep everything in one nice object.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">happiness_binary_ipw</span> <span class="op">&lt;-</span> <span class="va">happiness_binary</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>ipw <span class="op">=</span> <span class="va">weights_binary_ipw</span><span class="op">$</span><span class="va">ipw.weights</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_ate_binary_ipw</span> <span class="op">&lt;-</span> <span class="fu">lmer</span><span class="op">(</span><span class="va">happiness_policy</span> <span class="op">~</span> <span class="va">policy</span> <span class="op">+</span> <span class="va">lag_policy</span> <span class="op">+</span> </span>
<span>                               <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">country</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">year</span><span class="op">)</span>, </span>
<span>                             data <span class="op">=</span> <span class="va">happiness_binary_ipw</span>, weights <span class="op">=</span> <span class="va">ipw</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">model_ate_binary_ipw</span>, effects <span class="op">=</span> <span class="st">"fixed"</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 3 × 5</span></span>
<span><span class="co">##   effect term        estimate std.error statistic</span></span>
<span><span class="co">##   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span><span class="co">## 1 fixed  (Intercept)    51.9      1.26      41.2 </span></span>
<span><span class="co">## 2 fixed  policy          7.64     0.510     15.0 </span></span>
<span><span class="co">## 3 fixed  lag_policy     -1.30     0.448     -2.91</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section><section id="marginal-structural-model-with-a-continuous-treatment" class="level2"><h2 class="anchored" data-anchor-id="marginal-structural-model-with-a-continuous-treatment">Marginal structural model with a continuous treatment</h2>
<p>Here our main question is what the causal effect of mandated vacation time is on national happiness. This treatment is continuous—days of vacation. We don’t need to worry about having all 1s or all 0s and worry about zero-one inflated models or anything, since the treatment varies a lot across all countries and years.</p>
<section id="naive-estimate-without-weights-1" class="level3"><h3 class="anchored" data-anchor-id="naive-estimate-without-weights-1">Naive estimate without weights</h3>
<p>As before, we’ll look at the effect of vacation time is on happiness without any weights. Again, this is the approach in like a billion political science papers.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_naive</span> <span class="op">&lt;-</span> <span class="fu">feols</span><span class="op">(</span><span class="va">happiness_vacation</span> <span class="op">~</span> <span class="va">vacation_days</span> <span class="op">+</span> <span class="va">log_gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> </span>
<span>                       <span class="va">corruption</span> <span class="op">+</span> <span class="va">lag_happiness_vacation</span> <span class="op">+</span> <span class="va">lag_vacation_days</span> <span class="op">|</span> <span class="va">country</span> <span class="op">+</span> <span class="va">year</span>,</span>
<span>                data <span class="op">=</span> <span class="va">happiness_data</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">model_naive</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 6 × 5</span></span>
<span><span class="co">##   term                   estimate std.error statistic  p.value</span></span>
<span><span class="co">##   &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span><span class="co">## 1 vacation_days            2.12      0.129      16.4  1.94e-35</span></span>
<span><span class="co">## 2 log_gdp_cap              1.35      0.226       5.98 1.54e- 8</span></span>
<span><span class="co">## 3 democracy                0.0516    0.0156      3.31 1.17e- 3</span></span>
<span><span class="co">## 4 corruption              -0.0624    0.0224     -2.78 6.10e- 3</span></span>
<span><span class="co">## 5 lag_happiness_vacation   0.559     0.148       3.76 2.38e- 4</span></span>
<span><span class="co">## 6 lag_vacation_days       -1.35      0.382      -3.54 5.32e- 4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here we see that an additional day of vacation is associated with a 2.1-point increase in national happiness. Once again, this is wrong and biased, since there’s no weighting adjustment that deals with time-based confounding.</p>
</section><section id="manual-weights-1" class="level3"><h3 class="anchored" data-anchor-id="manual-weights-1">Manual weights</h3>
<p>We’ll follow the formula for continuous stabilized weights:</p>
<p><span class="math display">\[
\text{Continuous stabilized IPW}_{it} = \prod^t_{t = 1} \frac{f_{X | \bar{X}, V}[(X_{it} | \bar{X}_{i, t-1}, V_i); \mu_1, \sigma^2_1]}{f_{X | \bar{X}, Y, C, V}[(X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i), \mu_2, \sigma^2_2]}
\]</span></p>
<p>The numerator predicts the treatment using the previous treatment and time invariant confounders. We’ll use regular old linear regression here, but again, I’m like 90% sure you can do fancier things like multilevel models or machine learning or Bayes stuff:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_num</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vacation_days</span> <span class="op">~</span> <span class="va">lag_vacation_days</span> <span class="op">+</span> <span class="va">country</span>, </span>
<span>                data <span class="op">=</span> <span class="va">happiness_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This multilevel model works too</span></span>
<span><span class="co"># model_num &lt;- lmer(vacation_days ~ lag_vacation_days + (1 | country), </span></span>
<span><span class="co">#                   data = happiness_data)</span></span>
<span></span>
<span><span class="co"># Calculate the probability distribution</span></span>
<span><span class="va">num</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">happiness_data</span><span class="op">$</span><span class="va">vacation_days</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model_num</span><span class="op">)</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">model_num</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The denominator predicts the treatment using time-varying confounders, previous outcome, previous treatment, and time invariant confounders. Again we’ll use linear regression, but you can probably do fancier stuff too:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_denom</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vacation_days</span> <span class="op">~</span> <span class="va">log_gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> <span class="va">corruption</span> <span class="op">+</span> </span>
<span>                    <span class="va">lag_happiness_vacation</span> <span class="op">+</span> <span class="va">lag_vacation_days</span> <span class="op">+</span> <span class="va">country</span>, </span>
<span>                  data <span class="op">=</span> <span class="va">happiness_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This multilevel model works too</span></span>
<span><span class="co"># model_denom &lt;- lmer(vacation_days ~ log_gdp_cap + democracy + corruption + </span></span>
<span><span class="co">#                     lag_happiness_vacation + lag_vacation_days + (1 | country), </span></span>
<span><span class="co">#                   data = happiness_data)</span></span>
<span></span>
<span><span class="co"># Calculate the probability distribution</span></span>
<span><span class="va">den</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">happiness_data</span><span class="op">$</span><span class="va">vacation_days</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model_denom</span><span class="op">)</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">model_denom</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally we need to use the results from the numerator and denominator to build the inverse weights and calculate the cumulative product over time within each country:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Finally, we make actual IPW weights by building the fraction</span></span>
<span><span class="va">happiness_data_weights</span> <span class="op">&lt;-</span> <span class="va">happiness_data</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>weights_no_time <span class="op">=</span> <span class="va">num</span> <span class="op">/</span> <span class="va">den</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">country</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>ipw <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cumsum.html">cumprod</a></span><span class="op">(</span><span class="va">weights_no_time</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ungroup</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">happiness_data_weights</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">country</span>, <span class="va">year</span>, <span class="va">vacation_days</span>, <span class="va">happiness_vacation</span>, <span class="va">ipw</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 6 × 5</span></span>
<span><span class="co">##   country  year vacation_days happiness_vacation   ipw</span></span>
<span><span class="co">##   &lt;chr&gt;   &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span><span class="co">## 1 Mimim    2010            12               43.2 0.142</span></span>
<span><span class="co">## 2 Mimim    2011            14               45.1 1.50 </span></span>
<span><span class="co">## 3 Mimim    2012            16               52.7 1.13 </span></span>
<span><span class="co">## 4 Mimim    2013            17               52.7 0.941</span></span>
<span><span class="co">## 5 Mimim    2014            18               53.5 0.838</span></span>
<span><span class="co">## 6 Mimim    2015            20               61.4 0.457</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can use the weights to find the ATE, just like we did with the binary version. Again, I’m using a multilevel model instead of a GEE model, which I <em>think</em> is theoretically fine and legal.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_ate</span> <span class="op">&lt;-</span> <span class="fu">lmer</span><span class="op">(</span><span class="va">happiness_vacation</span> <span class="op">~</span> <span class="va">vacation_days</span> <span class="op">+</span> <span class="va">lag_vacation_days</span> <span class="op">+</span> </span>
<span>                    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">country</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">year</span><span class="op">)</span>, </span>
<span>                  data <span class="op">=</span> <span class="va">happiness_data_weights</span>, weights <span class="op">=</span> <span class="va">ipw</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">model_ate</span>, effects <span class="op">=</span> <span class="st">"fixed"</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 3 × 5</span></span>
<span><span class="co">##   effect term              estimate std.error statistic</span></span>
<span><span class="co">##   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span><span class="co">## 1 fixed  (Intercept)          23.4     1.82        12.9</span></span>
<span><span class="co">## 2 fixed  vacation_days         3.48    0.0908      38.4</span></span>
<span><span class="co">## 3 fixed  lag_vacation_days    -1.19    0.0957     -12.4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After correctly adjusting for all the time-varying confounding, the causal effect of an additional vacation day is 3.48 happiness points, which is bigger than the naive estimate of 2.1 that we found earlier.</p>
<p>HOWEVER, this isn’t what I built into the data?? In the simulated data, I made the vacation effect be 1.7. So either I did the simulation wrong and built the effect incorrectly and it’s not actually 1.7, or I’m misspecifying the model here. I’m pretty sure that the weights themselves are fine and correct—I copied the equation and code directly from <span class="citation" data-cites="BlackwellGlynn:2018">Blackwell and Glynn (<a href="#ref-BlackwellGlynn:2018" role="doc-biblioref">2018</a>)</span>’s replication data, and the weights and ATE are basically the same when using <code>ipwtm()</code>. I don’t know what’s going on. :(</p>
</section><section id="weights-with-the-ipw-package-1" class="level3"><h3 class="anchored" data-anchor-id="weights-with-the-ipw-package-1">Weights with the <strong>ipw</strong> package</h3>
<p>It’s also possible to use the <code>ipwtm()</code> function with continuous weights, but it runs <em>incredibly slowly</em> since it uses <code>geeglm()</code> behind the scenes to build the weights.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This takes forever! like multiple minutes</span></span>
<span><span class="va">weights_ipw_continuous</span> <span class="op">&lt;-</span> <span class="fu">ipwtm</span><span class="op">(</span></span>
<span>  exposure <span class="op">=</span> <span class="va">vacation_days</span>,</span>
<span>  family <span class="op">=</span> <span class="st">"gaussian"</span>,</span>
<span>  corstr <span class="op">=</span> <span class="st">"ar1"</span>,</span>
<span>  numerator <span class="op">=</span> <span class="op">~</span> <span class="va">lag_vacation_days</span> <span class="op">+</span> <span class="va">country</span>,  <span class="co"># Time invariant stuff</span></span>
<span>  denominator <span class="op">=</span> <span class="op">~</span> <span class="va">log_gdp_cap</span> <span class="op">+</span> <span class="va">democracy</span> <span class="op">+</span> <span class="va">corruption</span> <span class="op">+</span> </span>
<span>    <span class="va">lag_happiness_vacation</span> <span class="op">+</span> <span class="va">lag_vacation_days</span> <span class="op">+</span> <span class="va">country</span>,  <span class="co"># All confounders</span></span>
<span>  id <span class="op">=</span> <span class="va">country</span>,</span>
<span>  timevar <span class="op">=</span> <span class="va">year</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"all"</span>,</span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">happiness_data</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Because it uses GEE models for the numerator and denominator and accounts for autoregressive time structures in the data (that’s what the <code>costr = "ar1"</code> argument is for), the weights are not exactly the same as the ones we found using manual math, but they’re super close:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Pretty close!</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">weights_ipw_continuous</span><span class="op">$</span><span class="va">ipw.weights</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.142 1.505 1.126 0.941 0.838 0.457</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">happiness_data_weights</span><span class="op">$</span><span class="va">ipw</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.142 1.505 1.126 0.941 0.838 0.457</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally we can use the weights to find the ATE. It’s basically identical to the effect we found with the manual math. (BUT STILL NOT 1.7 FOR WHATEVER REASON.)</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">happiness_ipw</span> <span class="op">&lt;-</span> <span class="va">happiness_data</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>ipw <span class="op">=</span> <span class="va">weights_ipw_continuous</span><span class="op">$</span><span class="va">ipw.weights</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_ate_ipw</span> <span class="op">&lt;-</span> <span class="fu">lmer</span><span class="op">(</span><span class="va">happiness_vacation</span> <span class="op">~</span> <span class="va">vacation_days</span> <span class="op">+</span> <span class="va">lag_vacation_days</span> <span class="op">+</span> </span>
<span>                        <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">country</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">year</span><span class="op">)</span>, </span>
<span>                      data <span class="op">=</span> <span class="va">happiness_ipw</span>, weights <span class="op">=</span> <span class="va">ipw</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">model_ate_ipw</span>, effects <span class="op">=</span> <span class="st">"fixed"</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 3 × 5</span></span>
<span><span class="co">##   effect term              estimate std.error statistic</span></span>
<span><span class="co">##   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span><span class="co">## 1 fixed  (Intercept)          23.4     1.82        12.9</span></span>
<span><span class="co">## 2 fixed  vacation_days         3.48    0.0908      38.4</span></span>
<span><span class="co">## 3 fixed  lag_vacation_days    -1.19    0.0957     -12.4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section><section id="important-caveats" class="level2"><h2 class="anchored" data-anchor-id="important-caveats">Important caveats!</h2>
<p>This is just a quick practical overview of how to actually build IPWs and use MSMs. I didn’t cover any of the math behind MSMs or the assumptions behind them, their limitations, diagnostics you should do, etc. Like, weights should generally have an average of 1 and not have values that are too extreme (and if values are too extreme, you can/should truncate them).</p>
<p>ALSO I likely have something wrong here. If so, <em>let me know</em>! Download the simulated data, play with it, fix the MSMs and weights, and tell me what’s wrong. Please!</p>


<!-- -->


</section><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BlackwellGlynn:2018" class="csl-entry" role="listitem">
Blackwell, Matthew, and Adam N. Glynn. 2018. <span>“How to Make Causal Inferences with Time-Series Cross-Sectional Data Under Selection on Observables.”</span> <em>American Political Science Review</em> 112 (4): 1067–82. <a href="https://doi.org/10.1017/s0003055418000357">https://doi.org/10.1017/s0003055418000357</a>.
</div>
<div id="ref-ColeHernan:2008" class="csl-entry" role="listitem">
Cole, Stephen R., and Miguel A. Hernán. 2008. <span>“Constructing Inverse Probability Weights for Marginal Structural Models.”</span> <em>American Journal of Epidemiology</em> 168 (6): 656–64. <a href="https://doi.org/10.1093/aje/kwn164">https://doi.org/10.1093/aje/kwn164</a>.
</div>
<div id="ref-HernanRobins:2020" class="csl-entry" role="listitem">
Hernán, Miguel A., and James M. Robins. 2020. <em>Causal Inference: What If</em>. Boca Raton, Florida: <span>Chapman and Hall</span> / CRC. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/</a>.
</div>
<div id="ref-ImaiRatkovic:2015" class="csl-entry" role="listitem">
Imai, Kosuke, and Marc Ratkovic. 2015. <span>“Robust Estimation of Inverse Probability Weights for Marginal Structural Models.”</span> <em>Journal of the American Statistical Association</em> 110 (511): 1013–23. <a href="https://doi.org/10.1080/01621459.2014.956872">https://doi.org/10.1080/01621459.2014.956872</a>.
</div>
<div id="ref-RobinsHernanBrumback:2000" class="csl-entry" role="listitem">
Robins, James M., Miguel Ángel Hernán, and Babette Brumback. 2000. <span>“Marginal Structural Models and Causal Inference in Epidemiology.”</span> <em>Epidemiology</em> 11 (5): 550–60. <a href="https://doi.org/10.1097/00001648-200009000-00011">https://doi.org/10.1097/00001648-200009000-00011</a>.
</div>
<div id="ref-ThoemmesOng:2016" class="csl-entry" role="listitem">
Thoemmes, Felix, and Anthony D. Ong. 2016. <span>“A Primer on Inverse Probability of Treatment Weighting and Marginal Structural Models.”</span> <em>Emerging Adulthood</em> 4 (1): 40–59. <a href="https://doi.org/10.1177/2167696815621645">https://doi.org/10.1177/2167696815621645</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{heiss2020,
  author = {Heiss, Andrew},
  title = {Generating Inverse Probability Weights for Marginal
    Structural Models with Time-Series Cross-Sectional Panel Data},
  date = {2020-12-03},
  url = {https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/},
  doi = {10.59350/48w1z-xen07},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-heiss2020" class="csl-entry quarto-appendix-citeas" role="listitem">
Heiss, Andrew. 2020. <span>“Generating Inverse Probability Weights for
Marginal Structural Models with Time-Series Cross-Sectional Panel
Data.”</span> December 3, 2020. <a href="https://doi.org/10.59350/48w1z-xen07">https://doi.org/10.59350/48w1z-xen07</a>.
</div></div></section></div></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.andrewheiss\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><script src="https://giscus.app/client.js" data-repo="andrewheiss/ath-quarto" data-repo-id="R_kgDOIg6EJQ" data-category="Blog comments" data-category-id="DIC_kwDOIg6EJc4CSz92" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script><input type="hidden" id="giscus-base-theme" value="light"><input type="hidden" id="giscus-alt-theme" value="dark"><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data"</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2020-12-03</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments"</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> </span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - r</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - tidyverse</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - causal inference</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - DAGs</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - do calculus</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - inverse probability weighting</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> blackwell-glynn-fig-2.png</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="an">doi:</span><span class="co"> 10.59350/48w1z-xen07</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span><span class="co"> true</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include=FALSE}</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(fig.width = 6, fig.asp = 0.618, fig.align = "center", </span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="in">                      fig.retina = 3, out.width = "90%", collapse = TRUE)</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="in">options(digits = 3, width = 90)</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="in">options(dplyr.summarise.inform = FALSE)</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>In <span class="co">[</span><span class="ot">my post on generating inverse probability weights for both binary and continuous treatments</span><span class="co">](/blog/2020/12/01/ipw-binary-continuous/)</span>, I mentioned that I'd eventually need to figure out how to deal with more complex data structures and causal models where treatments, outcomes, and confounders vary over time. Instead of adjusting for DAG confounding with inverse probability weights, we need to use something called marginal structural models (MSMs) to make adjustments that account for treatment and outcome history and other time structures. This is complex stuff and social science hasn't done much with it (but it's been a common approach in epidemiology).</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>This post is my first attempt at teaching myself how to do this stuff. As I note at the end in the <span class="co">[</span><span class="ot">caveats section</span><span class="co">](#important-caveats)</span>, there might be (surely are!) mistakes. Please correct them!</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, warning=FALSE, message=FALSE}</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="in">library(tidyverse)</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="in">library(lme4)  # For mixed models</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="in">library(fixest)  # For fixed effects models</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="in">library(broom)</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a><span class="in">library(broom.mixed)  # For tidying mixed models</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="in">library(ggdag)</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="in">library(dagitty)</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="in">library(ipw)</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## DAGs and time-series cross-sectional (TSCS) data</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>Let's pretend that we're interested in the causal effect of a policy in a country on a country's happiness. We'll work with two different policies: whether a country implements a 6-hour workday (like <span class="co">[</span><span class="ot">Finland has been considering</span><span class="co">](https://www.forbes.com/sites/jackkelly/2020/01/08/finlands-prime-ministers-aspirational-goal-of-a-six-hour-four-day-workweek-will-this-ever-happen/?sh=79367a836384)</span>), which is binary, and the number of mandated vacation days a country provides, which is continuous. Both the policy and national happiness are influenced and confounded by a few different variables: general country-specific trends, GDP per capita, level of democratization, and level of political corruption. </span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>In the absence of time, this causal model is fairly straightforward:</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dag-simple, fig.width=6}</span></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="in">simple_dag &lt;- dagify(happiness ~ policy + gdp_cap + democracy + corruption + country,</span></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="in">                     policy ~ gdp_cap + democracy + corruption + country,</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a><span class="in">                     coords = list(x = c(policy = 1, happiness = 5, gdp_cap = 2, </span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a><span class="in">                                         democracy = 3, corruption = 4, country = 3),</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a><span class="in">                                   y = c(policy = 2, happiness = 2, gdp_cap = 3, </span></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a><span class="in">                                         democracy = 3.3, corruption = 3, country = 1)),</span></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="in">                     exposure = "policy",</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a><span class="in">                     outcome = "happiness")</span></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a><span class="in">ggdag_status(simple_dag, text_col = "black") +</span></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a><span class="in">  guides(color = "none") +</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_dag()</span></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>In a regular DAG setting, we can isolate the arrow between policy and happiness by statistically adjusting for all the nodes that open up backdoor relationships between them, or confound them. We can use *do*-calculus logic for that, or we can use R:</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dag-adjustment-simple}</span></span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a><span class="in">adjustmentSets(simple_dag)</span></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>Adjusting for the four confounders here is thus sufficient for closing all the backdoors and isolating the causal effect of the policy on national happiness. A standard approach to this kind of adjustment is inverse probability weighting, and I have <span class="co">[</span><span class="ot">a whole post about how to do that with both binary and continuous treatments</span><span class="co">](/blog/2020/12/01/ipw-binary-continuous/)</span> (as well as <span class="co">[</span><span class="ot">another post</span><span class="co">](/blog/2020/02/25/closing-backdoors-dags/)</span> and <span class="co">[</span><span class="ot">a textbook chapter</span><span class="co">](/research/chapters/heiss-causal-inference-2021/)</span> with even more details and examples).</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>However, in reality, time also influences policies, happiness, and other confounders. The number of vacation days a country offers in 2019 depends a lot on the number of vacation days offered in 2018, and 2017, and 2016, and so on. Also, a country's GDP, level of democracy, and level of corruption all depend on earlier values. Countries aren't just getting random levels of democracy each year! Not all confounders vary with time—country remains the same every year, as do things like region and continent.</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>On top of all that, happiness in a previous year could influence the policy in the current year. If a country has lower aggregate happiness in 2016, that could influences politicians' choice to mandate a 6-hour workday or increase vacation days in 2017 or 2018.</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>We need to incorporate time into our simple DAG. Because we're adding a bunch more nodes, I'm going to collapse the time-varying confounders (GDP per capita, democracy, and corruption) and time-invariant confounders (just country here) into single separate nodes. To account for time, I add $t$ subscripts: $t$ represents the current year, $t - 1$ (<span class="in">`t_m1`</span> in the graph) represents the previous year, $t - 2$ represents two years earlier, and so on.</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>Here's what this looks like:</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dag-complex, fig.width=9, out.width="100%"}</span></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a><span class="in">time_dag &lt;- dagify(happiness_t ~ policy_t + varying_confounders_t + happiness_tm1 + nonvarying_confounders,</span></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a><span class="in">                   policy_t ~ varying_confounders_t + happiness_tm1 + policy_tm1 + nonvarying_confounders,</span></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a><span class="in">                   varying_confounders_t ~ happiness_tm1 + varying_confounders_tm1 + nonvarying_confounders,</span></span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a><span class="in">                   happiness_tm1 ~ policy_tm1 + varying_confounders_tm1 + nonvarying_confounders,</span></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a><span class="in">                   policy_tm1 ~ varying_confounders_tm1 + nonvarying_confounders,</span></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a><span class="in">                   varying_confounders_tm1 ~ nonvarying_confounders,</span></span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a><span class="in">                   coords = list(x = c(happiness_t = 4, policy_t = 3, varying_confounders_t = 3, </span></span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a><span class="in">                                       happiness_tm1 = 2, policy_tm1 = 1, varying_confounders_tm1 = 1,</span></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a><span class="in">                                       nonvarying_confounders = 2.5),</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a><span class="in">                                 y = c(happiness_t = 3, policy_t = 2, varying_confounders_t = 4, </span></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a><span class="in">                                       happiness_tm1 = 3, policy_tm1 = 2, varying_confounders_tm1 = 4,</span></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a><span class="in">                                       nonvarying_confounders = 1)),</span></span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a><span class="in">                   exposure = "policy_t",</span></span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a><span class="in">                   outcome = "happiness_t")</span></span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a><span class="in">ggdag_status(time_dag, text_col = "black") +</span></span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a><span class="in">  guides(color = "none") +</span></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_dag()</span></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>Phew. That's bananas. And that's just for one time period. Technically there are also nodes from $t - 2$ and $t - 3$ and so on that influence $t - 1$. Figure 2 from @BlackwellGlynn:2018 shows a similar structure with previous time periods (though they don't have an arrow from $Y_{t-1}$ to $Y$):</span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a><span class="al">![Figure 2 from @BlackwellGlynn:2018](blackwell-glynn-fig-2.png)</span></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a>All we care about in this situation is the single arrow between <span class="in">`policy_t`</span> and <span class="in">`happiness_t`</span>. (There are ways of looking at other arrows, like the effect of <span class="in">`policy_tm1`</span> on <span class="in">`happiness_t`</span>, but we won't try to measure those here. @BlackwellGlynn:2018 show how to do that.)</span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>We can use *do*-calculus logic to see what nodes need to be adjusted for to isolate that arrow:</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dag-adjustment-complex}</span></span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a><span class="in">adjustmentSets(time_dag)</span></span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>According to this, we should adjust for time variant confounders in the current year, happiness in the previous year, and nonvarying confounders like country. *However*, this won't be completely accurate because the previous history matters. In general, situations where treatments, confounders, and outcomes vary over time, adjustment approaches like inverse probability weighting will be biased and incorrect. </span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a><span class="fu">## Marginal structural models</span></span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a>To account for this time structure, we can instead use something called marginal structural models (MSMs) to make DAG adjustments. These have been used widely in epidemiology, and there are some really great and accessible overviews of the method here:</span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Chapter 12 in <span class="co">[</span><span class="ot">Miguel A. Hernán and James M. Robins, *Causal Inference: What If*</span><span class="co">](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)</span> <span class="co">[</span><span class="ot">@HernanRobins:2020</span><span class="co">]</span></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Felix Thoemmes and Anthony D. Ong, "A Primer on Inverse Probability of Treatment Weighting and Marginal Structural Models" <span class="co">[</span><span class="ot">@ThoemmesOng:2016</span><span class="co">]</span></span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Stephen R. Cole and Miguel A. Hernán, "Constructing Inverse Probability Weights for Marginal Structural Models" <span class="co">[</span><span class="ot">@ColeHernan:2008</span><span class="co">]</span></span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Kosuke Imai and Marc Ratkovic, "Robust Estimation of Inverse Probability Weights for Marginal Structural Models" <span class="co">[</span><span class="ot">@ImaiRatkovic:2015</span><span class="co">]</span></span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>James M. Robins, Miguel Ángel Hernán, and Babette Brumback, "Marginal Structural Models and Causal Inference in Epidemiology" <span class="co">[</span><span class="ot">@RobinsHernanBrumback:2000</span><span class="co">]</span></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a>In my world of public policy and political science, though, MSMs are far rarer, even though ***tons of the data we use*** is time-series cross-sectional (TSCS) data, or panel data where each row represents a country and year (e.g. row 1 is Afghanistan in 2008, row 2 is Afghanistan in 2009, etc.) or state and year (e.g. Alabama 2015, Alabama 2016, etc.). The only paper I've really seen that uses MSMs in the political science world is @BlackwellGlynn:2018, which is an introduction to the topic and a call for using them more:</span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Matthew Blackwell and Adam N. Glynn, "How to Make Causal Inferences with Time-Series Cross-Sectional Data under Selection on Observables," <span class="co">[</span><span class="ot">@BlackwellGlynn:2018</span><span class="co">]</span></span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>The basic intuition behind MSMs is similar to <span class="co">[</span><span class="ot">simpler inverse probability weighting</span><span class="co">](blog/2020/12/01/ipw-binary-continuous/)</span>:</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate weights using confounders and the time structure</span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the average treatment effect using the weights and the time structure</span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a>The formula for calculating weights differs depending on if the treatment is binary or continuous, and they're written slightly differently across those different resources listed above.</span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>Here's my version of how to calculate stabilized inverse probability weights with a binary treatment:</span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a>\text{Binary stabilized IPW}_{it} = \prod^t_{t = 1} \frac{P[X_{it} | \bar{X}_{i, t-1}, V_i]}{P[X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i]}</span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a>There are a ton of variables in this equation. Let's go through them one at a time:</span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$i$ stands for an individual (person, country, etc.)</span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$t$ stands for a time period (year, month, day, etc.)</span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$X$ stands for the observed treatment status; $X_{it}$ stands for the observed treatment status of an individual at a given time. This is often written more specifically as $X_{it} = x_{it}$ (see equation 1 in p. 46 in @ThoemmesOng:2016, and [the equation at the beginning of this tutorial here](https://rpubs.com/mbounthavong/IPTW_MSM_Tutorial), for instance), but for simplicity I'll just write it as $X_{it}$.</span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\bar{X}$ stands for the individual's history of treatment assignment (e.g. all $X$ values in previous time periods)</span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$Y$ stands for the outcome; $Y_{it}$ stands for the outcome of an individual at a given time.</span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$C$ stands for time *varying* confounders; because these change over time, $C$ gets a $t$ subscript: $C_{it}$</span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$V$ stands for time *invarying* confounders; that's why there's no $t$ in $V_i$</span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Finally $P<span class="co">[</span><span class="ot">\cdot</span><span class="co">]</span>$ stands for the probability distribution</span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a>Here's a more human explanation:</span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The numerator contains the probability of the observed treatment status ($X$) at each time given the previous history of treatment ($\bar{X}$) and time *invariant* confounders ($V_i$)</span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The denominator contains the probability of the observed treatment status ($X$) at each time given the previous history of treatment ($\bar{X}$), previous outcomes ($Y_{i, t-1}$), time *varying* confounders ($C_{it}$) and time *invariant* confounders ($V_i$). The previous outcomes part ($Y_{i, t-1}$) is optional; if you think that the outcome's previous values influence current values, and the DAG shows an arrow from $Y_{t-1}$ and $Y_t$, include it.</span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a>Importantly, time varying confounders ($C_{it}$) are included in the denominator only, not the numerator. The lagged outcome ($Y_{i, t-1}$), if used, also only goes in the denominator.</span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>Technically the numerator can just be 1 instead of the whole $P<span class="co">[</span><span class="ot">\cdot</span><span class="co">]</span>$ thing, but that creates unstable weights. Using $P<span class="co">[</span><span class="ot">\cdot</span><span class="co">]</span>$ in the numerator creates stabilized weights.</span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>The equation for continuous weights looks really similar:</span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a>\text{Continuous stabilized IPW}_{it} = \prod^t_{t = 1} \frac{f_{X | \bar{X}, V}[(X_{it} | \bar{X}_{i, t-1}, V_i); \mu_1, \sigma^2_1]}{f_{X | \bar{X}, Y, C, V}[(X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i), \mu_2, \sigma^2_2]}</span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>Yikes. This is looks really complicated (and it is!), but again we can separate it into individual parts:</span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$X$, $Y$, $V$, $C$, $i$, and $t$ are all the same as the binary version of the formula</span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The numerator is still the treatment, treatment history, and time invariant confounders</span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The denominator is still the treatment, treatment history, previous outcome, time varying confounders, and time invariant confounders</span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The $f_{\cdot}(\cdot)$ functions are new and stand for a probability density function with a mean of $\mu$ and a variance of $\sigma^2$</span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a>That's a ton of information and it's all really abstract. Let's try this out with some simulated data</span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simulated time-series cross-sectional data</span></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>For this example, we'll use some data I generated with the **fabricatr** package, which makes it really easy to build multilevel and nested structures like country- and year-level variables. The actual code to generate this is a little long, mostly because it's heavily annotated and has a ton of intermediate variables. You can download the data here if you want to follow along with the rest of the code:</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">&lt;i class="fas fa-file-csv"&gt;&lt;/i&gt; `happiness_data.csv`</span><span class="co">](happiness_data.csv)</span></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">&lt;i class="fab fa-r-project"&gt;&lt;/i&gt; `happiness_simulation.R`</span><span class="co">](happiness_simulation.R)</span></span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a>It contains a bunch of different columns:</span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`country`</span>: The country name (generated as a pronouncable 5-letter sequence (<span class="co">[</span><span class="ot">proquint</span><span class="co">](https://arxiv.org/html/0901.4016)</span>) with the <span class="co">[</span><span class="ot">**ids** package</span><span class="co">](https://reside-ic.github.io/ids/)</span>)</span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`year`</span>: The year</span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`vacation_days`</span>: The number of mandated vacation days. This is a treatment variable.</span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`policy`</span>: An indicator for whether a country has passed a policy that mandates a 6-hour workday. This is another treatment variable</span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`happiness_vacation`</span>: The level of happiness in a country, on a scale of 1–100 (more happiness = higher values). This is the outcome when using <span class="in">`vacation_days`</span> as the treatment.</span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`happiness_policy`</span>: The level of happiness in a country. This is the outcome when using <span class="in">`policy`</span> as the treatment.</span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`log_populuation`</span>: Logged population</span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`log_gdp`</span>: Logged GDP</span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`gdp`</span>: GDP</span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`population`</span>: Population</span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`gdp_cap`</span>: GDP per capita</span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`log_gdp_cap`</span>: Logged GDP per capita</span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`democracy`</span>: The country's level of democracy, on a scale of 1–100 (more democratic = higher values)</span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`corruption`</span>: The level of political corruption in a country, on a scale of 1–100 (more corrupt = higher values)</span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`lag_*`</span>: Lagged versions of a bunch of different columns</span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a>And here's what the actual data looks like:</span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{r load-data, warning=FALSE, message=FALSE}</span></span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_data &lt;- read_csv("happiness_data.csv")</span></span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a><span class="in">glimpse(happiness_data)</span></span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a>We'll use this data explore two different questions:</span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Binary treatment: What is the effect of a 6-hour workday policy on national happiness?**</span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Continuous treatment: What is the effect of the number of mandated vacation days on national happiness?**</span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a><span class="fu">## Marginal structural model with a binary treatment</span></span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a>Before we do anything with the binary treatment, we need to filter the data a little. Because of the nature of the data, some of the fake countries never implement the policy and have all 0s in the <span class="in">`policy`</span> column. Weird things happen with the math of logistic regression if there are countries that have all 0s or all 1s for the outcome, since it's technically impossible to predict their outcomes. That's why <span class="co">[</span><span class="ot">zero-one inflated beta (ZOIB) models or hurdle models</span><span class="co">](https://vuorre.netlify.app/post/2019/02/18/analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/)</span> are a thing—they're two step models that first model if you do the policy at all, then model the probability of the policy if it does happen. Rather than deal with ZOIB stuff here, I made it so that all countries start with 0 for the policy (i.e. no country has the policy in the first year), and then here we filter out any countries that don't ever implement the policy.</span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-policy-subset}</span></span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_binary &lt;- happiness_data %&gt;% </span></span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(country) %&gt;% </span></span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(never_policy = all(policy == 0)) %&gt;% </span></span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a><span class="in">  ungroup() %&gt;% </span></span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a><span class="in">  filter(!never_policy)</span></span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a><span class="fu">### Naive estimate without weights</span></span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a>Before playing with MSMs, let's look at what the effect of the policy is on happiness without doing any inverse probability weighting for DAG adjustment. This is what most political science and international relations and public policy papers do. This is what I did in my dissertation and what I've done in a bunch of working papers. The wrongness of this approach is why I'm writing this post :)</span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a>This is just a regular linear regression model. I could run it with <span class="in">`lm()`</span>, but then a ton of country and year coefficients would be included by default in the results, so I use <span class="in">`feols()`</span> from the delightful **fixest** package to include country and year as fixed effects. The results from <span class="in">`feols()`</span> and <span class="in">`lm()`</span> are identical here; <span class="in">`feols()`</span> is cleaner and faster.</span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a><span class="in">```{r binary-model-naive}</span></span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a><span class="in">model_naive &lt;- feols(happiness_policy ~ policy + log_gdp_cap + democracy + </span></span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a><span class="in">                       corruption + lag_happiness_policy + lag_policy | country + year,</span></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a><span class="in">                data = happiness_binary)</span></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a><span class="in">tidy(model_naive)</span></span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a>According to this, implementing a 6-hour workday is associated with a 6.8-point increase in national happiness. This is wrong though! We need to generate and use time-adjusted inverse probability weights to adjust for these confounders.</span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a><span class="fu">### Manual weights</span></span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a>We'll follow this formula to use confounders and previous treatments and outcomes to generate stabilized weights:</span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a>\text{Binary stabilized IPW}_{it} = \prod^t_{t = 1} \frac{P[X_{it} | \bar{X}_{i, t-1}, V_i]}{P[X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i]}</span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a>The numerator predicts the treatment using the previous treatment and time invariant confounders. We'll use logistic regression here, but I'm like 90% sure you can do fancier things like multilevel models or machine learning or Bayes stuff:</span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-250"><a href="#cb23-250" aria-hidden="true" tabindex="-1"></a><span class="in">```{r binary-manual-numerator}</span></span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a><span class="in">model_num &lt;- glm(policy ~ lag_policy + country, </span></span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a><span class="in">                 data = happiness_binary, family = binomial(link = "logit"))</span></span>
<span id="cb23-253"><a href="#cb23-253" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-254"><a href="#cb23-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a>The denominator predicts the treatment using time-varying confounders, previous outcome, previous treatment, and time invariant confounders. Again we'll use logistic regression here, but you can probably do fancier stuff too:</span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-257"><a href="#cb23-257" aria-hidden="true" tabindex="-1"></a><span class="in">```{r binary-manual-denominator, warning=FALSE}</span></span>
<span id="cb23-258"><a href="#cb23-258" aria-hidden="true" tabindex="-1"></a><span class="in"># There's a warning that fitted probabiltiies of 0 or 1 occurred, likely because</span></span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a><span class="in"># my data is too perfect. Oh well---we'll live with it.</span></span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a><span class="in">model_denom &lt;- glm(policy ~ log_gdp_cap + democracy + corruption + </span></span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a><span class="in">                     lag_happiness_policy + lag_policy + country, </span></span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a><span class="in">                   data = happiness_binary, family = binomial(link = "logit"))</span></span>
<span id="cb23-263"><a href="#cb23-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-264"><a href="#cb23-264" aria-hidden="true" tabindex="-1"></a><span class="in"># This also works if you use fixest::feglm() for country fixed effects</span></span>
<span id="cb23-265"><a href="#cb23-265" aria-hidden="true" tabindex="-1"></a><span class="in"># model_denom &lt;- feglm(policy ~ log_gdp_cap + democracy + corruption +</span></span>
<span id="cb23-266"><a href="#cb23-266" aria-hidden="true" tabindex="-1"></a><span class="in">#                        lag_happiness_policy + lag_policy | country,</span></span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a><span class="in">#                      data = happiness_binary, family = binomial(link = "logit"))</span></span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-270"><a href="#cb23-270" aria-hidden="true" tabindex="-1"></a>Finally we need to use the results from the numerator and denominator to construct the weights following the equation:</span>
<span id="cb23-271"><a href="#cb23-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a><span class="in">```{r binary-manual-weights}</span></span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_binary_weights &lt;- happiness_binary %&gt;% </span></span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a><span class="in">  # Propensity scores from the models</span></span>
<span id="cb23-275"><a href="#cb23-275" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(propensity_num = model_num$fitted.values,</span></span>
<span id="cb23-276"><a href="#cb23-276" aria-hidden="true" tabindex="-1"></a><span class="in">         propensity_denom = model_denom$fitted.values) %&gt;% </span></span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a><span class="in">  # Probability of observed outcome</span></span>
<span id="cb23-278"><a href="#cb23-278" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(propensity_num_outcome = ifelse(policy == 1, propensity_num, 1 - propensity_num),</span></span>
<span id="cb23-279"><a href="#cb23-279" aria-hidden="true" tabindex="-1"></a><span class="in">         propensity_denom_outcome = ifelse(policy == 1, propensity_denom, 1 - propensity_denom)) %&gt;% </span></span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a><span class="in">  # Numerator / denominator</span></span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(weights_no_time = propensity_num_outcome / propensity_denom_outcome) %&gt;% </span></span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a><span class="in">  # Calculate the cumulative product of the weights within each country</span></span>
<span id="cb23-283"><a href="#cb23-283" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(country) %&gt;% </span></span>
<span id="cb23-284"><a href="#cb23-284" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(ipw = cumprod(weights_no_time)) %&gt;% </span></span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a><span class="in">  ungroup()</span></span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_binary_weights %&gt;% </span></span>
<span id="cb23-288"><a href="#cb23-288" aria-hidden="true" tabindex="-1"></a><span class="in">  select(country, year, policy, happiness_policy, ipw) %&gt;% </span></span>
<span id="cb23-289"><a href="#cb23-289" aria-hidden="true" tabindex="-1"></a><span class="in">  head()</span></span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a>Finally we'll use those weights in a regression model to estimate the average treatment effect (ATE) of the policy on happiness. We need to use a model that accounts for the year and country panel structure for this. In every tutorial I've seen online, people use <span class="in">`geeglm()`</span> from the <span class="co">[</span><span class="ot">**geepack** package</span><span class="co">](https://cran.r-project.org/package=geepack)</span>, which lets you specify country and year dimensions in generalized estimating equations. These feel an awful lot like mixed models with random country/year effects. There's some useful discussion and useful links about the differences between GEE models and multilevel models <span class="co">[</span><span class="ot">in this Twitter thread here</span><span class="co">](https://twitter.com/andrewheiss/status/1317634713935380480)</span>. For the sake of this example, I'll use multilevel models since I'm more familiar with them, and because you can build Bayesian ones with the <span class="co">[</span><span class="ot">**brms** package</span><span class="co">](https://paul-buerkner.github.io/brms/)</span>; I have yet to find a Bayesian flavor of GEEs.</span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a>In the outcome model, we include the previous treatment history and the invariant confounders (<span class="in">`country`</span>, which I include as a random effect). To account for the time structure in the data, I also include a year random effect.</span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a><span class="in">```{r binary-manual-ate}</span></span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a><span class="in">model_ate_binary &lt;- lmer(happiness_policy ~ policy + lag_policy + </span></span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a><span class="in">                           (1 | country) + (1 | year), </span></span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a><span class="in">                  data = happiness_binary_weights, weights = ipw)</span></span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a><span class="in">tidy(model_ate_binary, effects = "fixed")</span></span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a>Voila! After adjusting for time-varying confounders and previous treatment history, the 6-hour workday policy *causes* an increase of 7.6 happiness points, on average. This is actually the effect that I built into the data. It worked!</span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-305"><a href="#cb23-305" aria-hidden="true" tabindex="-1"></a>However, I'm still not 100% confident that it did work. There are a lot of different moving parts here, and I'm not sure I have the right covariates in the right place (like in the outcome model, I'm fairly certain the model should be <span class="in">`happiness_policy ~ policy + lag_policy`</span>, but I'm not sure).</span>
<span id="cb23-306"><a href="#cb23-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a>Also the standard errors in this outcome model are wrong and have to be adjusted, either with fancy math or with bootstrapping (@BlackwellGlynn:2018 use boostrapping).</span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a>But still, this is really neat.</span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a><span class="fu">### Weights with the **ipw** package</span></span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a>Instead of manually doing all the math to generate the weights, we can use the <span class="in">`ipwtm()`</span> function from the <span class="co">[</span><span class="ot">**ipw** package</span><span class="co">](https://cran.r-project.org/package=ipw)</span> to do it for us. We still specify a numerator and denominator, but the function takes care of the rest of the math. The numbers are the same.</span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a><span class="in">```{r binary-ipw-weights, warning=FALSE}</span></span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a><span class="in"># ipwtm() can't handle tibbles! Force the data to be a data.frame</span></span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a><span class="in">weights_binary_ipw &lt;- ipwtm(</span></span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a><span class="in">  exposure = policy,</span></span>
<span id="cb23-320"><a href="#cb23-320" aria-hidden="true" tabindex="-1"></a><span class="in">  family = "binomial",</span></span>
<span id="cb23-321"><a href="#cb23-321" aria-hidden="true" tabindex="-1"></a><span class="in">  link = "logit",</span></span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a><span class="in">  # Time invariant stuff</span></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a><span class="in">  numerator = ~ lag_policy + country,</span></span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a><span class="in">  # All confounders</span></span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a><span class="in">  denominator = ~ log_gdp_cap + democracy + corruption + </span></span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a><span class="in">    lag_happiness_policy + lag_policy + country,</span></span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a><span class="in">  id = country,</span></span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a><span class="in">  timevar = year,</span></span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a><span class="in">  type = "all",</span></span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a><span class="in">  data = as.data.frame(happiness_binary)</span></span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a><span class="in"># They're the same!</span></span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a><span class="in">head(weights_binary_ipw$ipw.weights)</span></span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a><span class="in">head(happiness_binary_weights$ipw)</span></span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a>This <span class="in">`weights_binary_ipw`</span> object contains a bunch of other information too, but all we really care about here is what's in the <span class="in">`ipw.weights`</span> slot. We can add those weights as a column in a dataset and run the outcome model, which will give us the same ATE as before (unsurprisingly, since they're identical). Technically we don't need to add a new column with the weights—the model will work if they're a standalone vector—but I don't like mixing data frames and standalone vectors and prefer to keep everything in one nice object.</span>
<span id="cb23-339"><a href="#cb23-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-340"><a href="#cb23-340" aria-hidden="true" tabindex="-1"></a><span class="in">```{r binary-ipw-ate}</span></span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_binary_ipw &lt;- happiness_binary %&gt;% </span></span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(ipw = weights_binary_ipw$ipw.weights)</span></span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-344"><a href="#cb23-344" aria-hidden="true" tabindex="-1"></a><span class="in">model_ate_binary_ipw &lt;- lmer(happiness_policy ~ policy + lag_policy + </span></span>
<span id="cb23-345"><a href="#cb23-345" aria-hidden="true" tabindex="-1"></a><span class="in">                               (1 | country) + (1 | year), </span></span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a><span class="in">                             data = happiness_binary_ipw, weights = ipw)</span></span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a><span class="in">tidy(model_ate_binary_ipw, effects = "fixed")</span></span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a><span class="fu">## Marginal structural model with a continuous treatment</span></span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-353"><a href="#cb23-353" aria-hidden="true" tabindex="-1"></a>Here our main question is what the causal effect of mandated vacation time is on national happiness. This treatment is continuous—days of vacation. We don't need to worry about having all 1s or all 0s and worry about zero-one inflated models or anything, since the treatment varies a lot across all countries and years.</span>
<span id="cb23-354"><a href="#cb23-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a><span class="fu">### Naive estimate without weights</span></span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-357"><a href="#cb23-357" aria-hidden="true" tabindex="-1"></a>As before, we'll look at the effect of vacation time is on happiness without any weights. Again, this is the approach in like a billion political science papers.</span>
<span id="cb23-358"><a href="#cb23-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a><span class="in">```{r continuous-model-naive}</span></span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a><span class="in">model_naive &lt;- feols(happiness_vacation ~ vacation_days + log_gdp_cap + democracy + </span></span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a><span class="in">                       corruption + lag_happiness_vacation + lag_vacation_days | country + year,</span></span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a><span class="in">                data = happiness_data)</span></span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a><span class="in">tidy(model_naive)</span></span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-366"><a href="#cb23-366" aria-hidden="true" tabindex="-1"></a>Here we see that an additional day of vacation is associated with a 2.1-point increase in national happiness. Once again, this is wrong and biased, since there's no weighting adjustment that deals with time-based confounding.</span>
<span id="cb23-367"><a href="#cb23-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a><span class="fu">### Manual weights</span></span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a>We'll follow the formula for continuous stabilized weights:</span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a>\text{Continuous stabilized IPW}_{it} = \prod^t_{t = 1} \frac{f_{X | \bar{X}, V}[(X_{it} | \bar{X}_{i, t-1}, V_i); \mu_1, \sigma^2_1]}{f_{X | \bar{X}, Y, C, V}[(X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i), \mu_2, \sigma^2_2]}</span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a>The numerator predicts the treatment using the previous treatment and time invariant confounders. We'll use regular old linear regression here, but again, I'm like 90% sure you can do fancier things like multilevel models or machine learning or Bayes stuff:</span>
<span id="cb23-377"><a href="#cb23-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-378"><a href="#cb23-378" aria-hidden="true" tabindex="-1"></a><span class="in">```{r continuous-manual-numerator}</span></span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a><span class="in">model_num &lt;- lm(vacation_days ~ lag_vacation_days + country, </span></span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a><span class="in">                data = happiness_data)</span></span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a><span class="in"># This multilevel model works too</span></span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a><span class="in"># model_num &lt;- lmer(vacation_days ~ lag_vacation_days + (1 | country), </span></span>
<span id="cb23-384"><a href="#cb23-384" aria-hidden="true" tabindex="-1"></a><span class="in">#                   data = happiness_data)</span></span>
<span id="cb23-385"><a href="#cb23-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a><span class="in"># Calculate the probability distribution</span></span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a><span class="in">num &lt;- dnorm(happiness_data$vacation_days,</span></span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a><span class="in">             predict(model_num),</span></span>
<span id="cb23-389"><a href="#cb23-389" aria-hidden="true" tabindex="-1"></a><span class="in">             sd(residuals(model_num)))</span></span>
<span id="cb23-390"><a href="#cb23-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-392"><a href="#cb23-392" aria-hidden="true" tabindex="-1"></a>The denominator predicts the treatment using time-varying confounders, previous outcome, previous treatment, and time invariant confounders. Again we'll use linear regression, but you can probably do fancier stuff too:</span>
<span id="cb23-393"><a href="#cb23-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a><span class="in">```{r continuous-manual-denominator, warning=FALSE}</span></span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a><span class="in">model_denom &lt;- lm(vacation_days ~ log_gdp_cap + democracy + corruption + </span></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a><span class="in">                    lag_happiness_vacation + lag_vacation_days + country, </span></span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a><span class="in">                  data = happiness_data)</span></span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a><span class="in"># This multilevel model works too</span></span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a><span class="in"># model_denom &lt;- lmer(vacation_days ~ log_gdp_cap + democracy + corruption + </span></span>
<span id="cb23-401"><a href="#cb23-401" aria-hidden="true" tabindex="-1"></a><span class="in">#                     lag_happiness_vacation + lag_vacation_days + (1 | country), </span></span>
<span id="cb23-402"><a href="#cb23-402" aria-hidden="true" tabindex="-1"></a><span class="in">#                   data = happiness_data)</span></span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a><span class="in"># Calculate the probability distribution</span></span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a><span class="in">den &lt;- dnorm(happiness_data$vacation_days,</span></span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a><span class="in">             predict(model_denom),</span></span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a><span class="in">             sd(residuals(model_denom)))</span></span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-409"><a href="#cb23-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-410"><a href="#cb23-410" aria-hidden="true" tabindex="-1"></a>Finally we need to use the results from the numerator and denominator to build the inverse weights and calculate the cumulative product over time within each country:</span>
<span id="cb23-411"><a href="#cb23-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-412"><a href="#cb23-412" aria-hidden="true" tabindex="-1"></a><span class="in">```{r continuous-manual-weights}</span></span>
<span id="cb23-413"><a href="#cb23-413" aria-hidden="true" tabindex="-1"></a><span class="in"># Finally, we make actual IPW weights by building the fraction</span></span>
<span id="cb23-414"><a href="#cb23-414" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_data_weights &lt;- happiness_data %&gt;% </span></span>
<span id="cb23-415"><a href="#cb23-415" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(weights_no_time = num / den) %&gt;% </span></span>
<span id="cb23-416"><a href="#cb23-416" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(country) %&gt;% </span></span>
<span id="cb23-417"><a href="#cb23-417" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(ipw = cumprod(weights_no_time)) %&gt;% </span></span>
<span id="cb23-418"><a href="#cb23-418" aria-hidden="true" tabindex="-1"></a><span class="in">  ungroup()</span></span>
<span id="cb23-419"><a href="#cb23-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-420"><a href="#cb23-420" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_data_weights %&gt;% </span></span>
<span id="cb23-421"><a href="#cb23-421" aria-hidden="true" tabindex="-1"></a><span class="in">  select(country, year, vacation_days, happiness_vacation, ipw) %&gt;% </span></span>
<span id="cb23-422"><a href="#cb23-422" aria-hidden="true" tabindex="-1"></a><span class="in">  head()</span></span>
<span id="cb23-423"><a href="#cb23-423" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-424"><a href="#cb23-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-425"><a href="#cb23-425" aria-hidden="true" tabindex="-1"></a>Now we can use the weights to find the ATE, just like we did with the binary version. Again, I'm using a multilevel model instead of a GEE model, which I *think* is theoretically fine and legal.</span>
<span id="cb23-426"><a href="#cb23-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-427"><a href="#cb23-427" aria-hidden="true" tabindex="-1"></a><span class="in">```{r continuous-manual-ate}</span></span>
<span id="cb23-428"><a href="#cb23-428" aria-hidden="true" tabindex="-1"></a><span class="in">model_ate &lt;- lmer(happiness_vacation ~ vacation_days + lag_vacation_days + </span></span>
<span id="cb23-429"><a href="#cb23-429" aria-hidden="true" tabindex="-1"></a><span class="in">                    (1 | country) + (1 | year), </span></span>
<span id="cb23-430"><a href="#cb23-430" aria-hidden="true" tabindex="-1"></a><span class="in">                  data = happiness_data_weights, weights = ipw)</span></span>
<span id="cb23-431"><a href="#cb23-431" aria-hidden="true" tabindex="-1"></a><span class="in">tidy(model_ate, effects = "fixed")</span></span>
<span id="cb23-432"><a href="#cb23-432" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-433"><a href="#cb23-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-434"><a href="#cb23-434" aria-hidden="true" tabindex="-1"></a>After correctly adjusting for all the time-varying confounding, the causal effect of an additional vacation day is 3.48 happiness points, which is bigger than the naive estimate of 2.1 that we found earlier.</span>
<span id="cb23-435"><a href="#cb23-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-436"><a href="#cb23-436" aria-hidden="true" tabindex="-1"></a>HOWEVER, this isn't what I built into the data?? In the simulated data, I made the vacation effect be 1.7. So either I did the simulation wrong and built the effect incorrectly and it's not actually 1.7, or I'm misspecifying the model here. I'm pretty sure that the weights themselves are fine and correct—I copied the equation and code directly from @BlackwellGlynn:2018's replication data, and the weights and ATE are basically the same when using <span class="in">`ipwtm()`</span>. I don't know what's going on. :(</span>
<span id="cb23-437"><a href="#cb23-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-438"><a href="#cb23-438" aria-hidden="true" tabindex="-1"></a><span class="fu">### Weights with the **ipw** package</span></span>
<span id="cb23-439"><a href="#cb23-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-440"><a href="#cb23-440" aria-hidden="true" tabindex="-1"></a>It's also possible to use the <span class="in">`ipwtm()`</span> function with continuous weights, but it runs *incredibly slowly* since it uses <span class="in">`geeglm()`</span> behind the scenes to build the weights.</span>
<span id="cb23-441"><a href="#cb23-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-442"><a href="#cb23-442" aria-hidden="true" tabindex="-1"></a><span class="in">```{r load-pre-done-weights, include=FALSE}</span></span>
<span id="cb23-443"><a href="#cb23-443" aria-hidden="true" tabindex="-1"></a><span class="in">weights_ipw_continuous &lt;- readRDS("continuous_ipwtm.rds")</span></span>
<span id="cb23-444"><a href="#cb23-444" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-445"><a href="#cb23-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-446"><a href="#cb23-446" aria-hidden="true" tabindex="-1"></a><span class="in">```{r ipw-weights-fake, eval=FALSE}</span></span>
<span id="cb23-447"><a href="#cb23-447" aria-hidden="true" tabindex="-1"></a><span class="in"># This takes forever! like multiple minutes</span></span>
<span id="cb23-448"><a href="#cb23-448" aria-hidden="true" tabindex="-1"></a><span class="in">weights_ipw_continuous &lt;- ipwtm(</span></span>
<span id="cb23-449"><a href="#cb23-449" aria-hidden="true" tabindex="-1"></a><span class="in">  exposure = vacation_days,</span></span>
<span id="cb23-450"><a href="#cb23-450" aria-hidden="true" tabindex="-1"></a><span class="in">  family = "gaussian",</span></span>
<span id="cb23-451"><a href="#cb23-451" aria-hidden="true" tabindex="-1"></a><span class="in">  corstr = "ar1",</span></span>
<span id="cb23-452"><a href="#cb23-452" aria-hidden="true" tabindex="-1"></a><span class="in">  numerator = ~ lag_vacation_days + country,  # Time invariant stuff</span></span>
<span id="cb23-453"><a href="#cb23-453" aria-hidden="true" tabindex="-1"></a><span class="in">  denominator = ~ log_gdp_cap + democracy + corruption + </span></span>
<span id="cb23-454"><a href="#cb23-454" aria-hidden="true" tabindex="-1"></a><span class="in">    lag_happiness_vacation + lag_vacation_days + country,  # All confounders</span></span>
<span id="cb23-455"><a href="#cb23-455" aria-hidden="true" tabindex="-1"></a><span class="in">  id = country,</span></span>
<span id="cb23-456"><a href="#cb23-456" aria-hidden="true" tabindex="-1"></a><span class="in">  timevar = year,</span></span>
<span id="cb23-457"><a href="#cb23-457" aria-hidden="true" tabindex="-1"></a><span class="in">  type = "all",</span></span>
<span id="cb23-458"><a href="#cb23-458" aria-hidden="true" tabindex="-1"></a><span class="in">  data = as.data.frame(happiness_data)</span></span>
<span id="cb23-459"><a href="#cb23-459" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb23-460"><a href="#cb23-460" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-461"><a href="#cb23-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-462"><a href="#cb23-462" aria-hidden="true" tabindex="-1"></a><span class="in">```{r save-ipw-weights-fake, eval=FALSE, include=FALSE}</span></span>
<span id="cb23-463"><a href="#cb23-463" aria-hidden="true" tabindex="-1"></a><span class="in">saveRDS(weights_ipw_continuous, "continuous_ipwtm.rds")</span></span>
<span id="cb23-464"><a href="#cb23-464" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-465"><a href="#cb23-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-466"><a href="#cb23-466" aria-hidden="true" tabindex="-1"></a>Because it uses GEE models for the numerator and denominator and accounts for autoregressive time structures in the data (that's what the <span class="in">`costr = "ar1"`</span> argument is for), the weights are not exactly the same as the ones we found using manual math, but they're super close:</span>
<span id="cb23-467"><a href="#cb23-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-468"><a href="#cb23-468" aria-hidden="true" tabindex="-1"></a><span class="in">```{r compare-manual-ipw}</span></span>
<span id="cb23-469"><a href="#cb23-469" aria-hidden="true" tabindex="-1"></a><span class="in"># Pretty close!</span></span>
<span id="cb23-470"><a href="#cb23-470" aria-hidden="true" tabindex="-1"></a><span class="in">head(weights_ipw_continuous$ipw.weights)</span></span>
<span id="cb23-471"><a href="#cb23-471" aria-hidden="true" tabindex="-1"></a><span class="in">head(happiness_data_weights$ipw)</span></span>
<span id="cb23-472"><a href="#cb23-472" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-473"><a href="#cb23-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-474"><a href="#cb23-474" aria-hidden="true" tabindex="-1"></a>Finally we can use the weights to find the ATE. It's basically identical to the effect we found with the manual math. (BUT STILL NOT 1.7 FOR WHATEVER REASON.)</span>
<span id="cb23-475"><a href="#cb23-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-476"><a href="#cb23-476" aria-hidden="true" tabindex="-1"></a><span class="in">```{r ipw-continuous-ate}</span></span>
<span id="cb23-477"><a href="#cb23-477" aria-hidden="true" tabindex="-1"></a><span class="in">happiness_ipw &lt;- happiness_data %&gt;% </span></span>
<span id="cb23-478"><a href="#cb23-478" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(ipw = weights_ipw_continuous$ipw.weights)</span></span>
<span id="cb23-479"><a href="#cb23-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-480"><a href="#cb23-480" aria-hidden="true" tabindex="-1"></a><span class="in">model_ate_ipw &lt;- lmer(happiness_vacation ~ vacation_days + lag_vacation_days + </span></span>
<span id="cb23-481"><a href="#cb23-481" aria-hidden="true" tabindex="-1"></a><span class="in">                        (1 | country) + (1 | year), </span></span>
<span id="cb23-482"><a href="#cb23-482" aria-hidden="true" tabindex="-1"></a><span class="in">                      data = happiness_ipw, weights = ipw)</span></span>
<span id="cb23-483"><a href="#cb23-483" aria-hidden="true" tabindex="-1"></a><span class="in">tidy(model_ate_ipw, effects = "fixed")</span></span>
<span id="cb23-484"><a href="#cb23-484" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-485"><a href="#cb23-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-486"><a href="#cb23-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-487"><a href="#cb23-487" aria-hidden="true" tabindex="-1"></a><span class="fu">## Important caveats!</span></span>
<span id="cb23-488"><a href="#cb23-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-489"><a href="#cb23-489" aria-hidden="true" tabindex="-1"></a>This is just a quick practical overview of how to actually build IPWs and use MSMs. I didn't cover any of the math behind MSMs or the assumptions behind them, their limitations, diagnostics you should do, etc. Like, weights should generally have an average of 1 and not have values that are too extreme (and if values are too extreme, you can/should truncate them). </span>
<span id="cb23-490"><a href="#cb23-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-491"><a href="#cb23-491" aria-hidden="true" tabindex="-1"></a>ALSO I likely have something wrong here. If so, *let me know*! Download the simulated data, play with it, fix the MSMs and weights, and tell me what's wrong. Please!</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i> 2007–2024 Andrew Heiss</span> <span class="faux-block">All content licensed under<br><a href="https://creativecommons.org/licenses/by/4.0/"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i> <i class="fa-brands fa-creative-commons-by" aria-label="creative-commons-by"></i> Creative Commons CC BY 4.0</a></span></p>
</div>   
    <div class="nav-footer-center">
<p><span class="faux-block"><i class="fa-brands fa-orcid" aria-label="orcid"></i> <strong>ORCID</strong> <a href="https://orcid.org/0000-0002-3948-3914">0000-0002-3948-3914</a></span> <span class="faux-block"><i class="fa-solid fa-key" aria-label="key"></i> <a href="../../../../../pgp_ath.asc.txt">PGP public key</a>   <i class="fa-solid fa-fingerprint" aria-label="fingerprint"></i> Fingerprint:<br><span class="fingerprint">4AA2 FA83 A8B2 05A4 E30F<br> 610D 1382 6216 9178 36AB</span></span></p>
</div>
    <div class="nav-footer-right">
<p><span class="faux-block">Made with <i class="fa-brands fa-r-project" aria-label="r-project"></i> and <a href="https://quarto.org/">Quarto</a></span> <span class="faux-block"><a href="https://github.com/andrewheiss/ath-quarto">View the source at <i class="fa-brands fa-github" aria-label="github"></i> GitHub</a></span></p>
</div>
  </div>
</footer>


</body></html>